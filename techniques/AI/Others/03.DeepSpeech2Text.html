<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.17" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.58" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://jet-w.github.io/techniques/AI/Others/03.DeepSpeech2Text.html"><meta property="og:site_name" content="Haiyue's Blog"><meta property="og:title" content="Audio to Text (DeepSpeech)"><meta property="og:description" content="What is DeepSpeech DeepSpeech is an open source Python library that enables us to build automatic speech ecognition systems. It is based on Baidu’s 2014 paper titled Deep Speech..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="article:author" content="Haiyue"><meta property="article:tag" content="audio2text"><meta property="article:published_time" content="2023-11-27T00:00:00.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Audio to Text (DeepSpeech)","image":[""],"datePublished":"2023-11-27T00:00:00.000Z","dateModified":null,"author":[{"@type":"Person","name":"Haiyue"}]}</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-4BP2YK8NPN" type="text/javascript"></script><script src="/src/gtag.js" type="text/javascript"></script><title>Audio to Text (DeepSpeech) | Haiyue's Blog</title><meta name="description" content="What is DeepSpeech DeepSpeech is an open source Python library that enables us to build automatic speech ecognition systems. It is based on Baidu’s 2014 paper titled Deep Speech...">
    <link rel="preload" href="/assets/style-BnwXs0fd.css" as="style"><link rel="stylesheet" href="/assets/style-BnwXs0fd.css">
    <link rel="modulepreload" href="/assets/app-CQersmFQ.js"><link rel="modulepreload" href="/assets/03.DeepSpeech2Text.html-tmNDHf-Q.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-Coci8DX2.js" as="script"><link rel="prefetch" href="/assets/intro.html-D3we3e4Z.js" as="script"><link rel="prefetch" href="/assets/常用药.html-DaMlXZWZ.js" as="script"><link rel="prefetch" href="/assets/index.html-CalR6Nh9.js" as="script"><link rel="prefetch" href="/assets/disable.html-C17FpWru.js" as="script"><link rel="prefetch" href="/assets/encrypt.html-oL6LZWb5.js" as="script"><link rel="prefetch" href="/assets/layout.html-BspEza5I.js" as="script"><link rel="prefetch" href="/assets/markdown.html-DaRyen7W.js" as="script"><link rel="prefetch" href="/assets/page.html-CsdLRlww.js" as="script"><link rel="prefetch" href="/assets/index.html-BGlvcJT7.js" as="script"><link rel="prefetch" href="/assets/index.html-tTnwKxUj.js" as="script"><link rel="prefetch" href="/assets/index.html-jW_a6rgr.js" as="script"><link rel="prefetch" href="/assets/index.html-B7vlb7He.js" as="script"><link rel="prefetch" href="/assets/index.html-DAKesztJ.js" as="script"><link rel="prefetch" href="/assets/index.html-2999bEwv.js" as="script"><link rel="prefetch" href="/assets/web_solarsystem.html-BxalfEm1.js" as="script"><link rel="prefetch" href="/assets/CDM.html-pNkb9FZl.js" as="script"><link rel="prefetch" href="/assets/QMatrix-TaskManagement.html-DTutRrV4.js" as="script"><link rel="prefetch" href="/assets/QMatrix2.html-BCmQ6tnq.js" as="script"><link rel="prefetch" href="/assets/QMatrix3.html-BW090d4S.js" as="script"><link rel="prefetch" href="/assets/index.html-BXmEwMSO.js" as="script"><link rel="prefetch" href="/assets/index.html-CLjeNkNp.js" as="script"><link rel="prefetch" href="/assets/VisualAnalytics.html-BDVZzCQP.js" as="script"><link rel="prefetch" href="/assets/index.html-DTDuHXGj.js" as="script"><link rel="prefetch" href="/assets/variables.html-2x0QXWD8.js" as="script"><link rel="prefetch" href="/assets/LLM_Constellation_Architecture_for_Healthcare.html-DfjjbK2c.js" as="script"><link rel="prefetch" href="/assets/index.html-Cekh1ely.js" as="script"><link rel="prefetch" href="/assets/index.html-CQBkFTJa.js" as="script"><link rel="prefetch" href="/assets/index.html-95r9Qwnn.js" as="script"><link rel="prefetch" href="/assets/Platforms.html-BRwdLnhQ.js" as="script"><link rel="prefetch" href="/assets/index.html-fZ1tF8pN.js" as="script"><link rel="prefetch" href="/assets/index.html-Bcw0x5um.js" as="script"><link rel="prefetch" href="/assets/UnisaRes.html-6AKosfyl.js" as="script"><link rel="prefetch" href="/assets/485.html-BP4jZRUW.js" as="script"><link rel="prefetch" href="/assets/index.html-DOlJ17Se.js" as="script"><link rel="prefetch" href="/assets/index.html-DUxmP-u0.js" as="script"><link rel="prefetch" href="/assets/Amplify.html-BsdcbFAF.js" as="script"><link rel="prefetch" href="/assets/CLI.html-EIDiXMfQ.js" as="script"><link rel="prefetch" href="/assets/DynamoDB.html-DEnmJJp-.js" as="script"><link rel="prefetch" href="/assets/Lambda.html-CqKjWRPB.js" as="script"><link rel="prefetch" href="/assets/index.html-BoPcZ0cI.js" as="script"><link rel="prefetch" href="/assets/SingleTable.html-C2eeg-x6.js" as="script"><link rel="prefetch" href="/assets/index.html-FRoeX55s.js" as="script"><link rel="prefetch" href="/assets/index.html-l-TPTad4.js" as="script"><link rel="prefetch" href="/assets/comm_cmd.html-BK49OQIG.js" as="script"><link rel="prefetch" href="/assets/index.html-BjqDMKZ5.js" as="script"><link rel="prefetch" href="/assets/basictools.html-C6N7vZKD.js" as="script"><link rel="prefetch" href="/assets/index.html-BduJH9GZ.js" as="script"><link rel="prefetch" href="/assets/make.html-BFVD1oQg.js" as="script"><link rel="prefetch" href="/assets/test.html-CslZIbt5.js" as="script"><link rel="prefetch" href="/assets/index.html-CQm7_rHQ.js" as="script"><link rel="prefetch" href="/assets/index.html-CC8N7GaX.js" as="script"><link rel="prefetch" href="/assets/youtube.html-cVHt6Ww5.js" as="script"><link rel="prefetch" href="/assets/index.html-CxkdT1Yw.js" as="script"><link rel="prefetch" href="/assets/q_a.html-DJ5b_gsi.js" as="script"><link rel="prefetch" href="/assets/index.html-qi0vm_GB.js" as="script"><link rel="prefetch" href="/assets/load_cifs.html-Be8gK4Re.js" as="script"><link rel="prefetch" href="/assets/ssh.html-ByCzRjFG.js" as="script"><link rel="prefetch" href="/assets/index.html-DN5A6LX2.js" as="script"><link rel="prefetch" href="/assets/01.Index.html-yhesVgQZ.js" as="script"><link rel="prefetch" href="/assets/02.Meeting.html-DtEuQ4dO.js" as="script"><link rel="prefetch" href="/assets/03.MotifsInTemporalNetworks.html-Cv-3BsuR.js" as="script"><link rel="prefetch" href="/assets/04.FeedbackSeekingBehivour.html-uAsZDFfa.js" as="script"><link rel="prefetch" href="/assets/05.Levels2ReflectiveText.html-YP7562vL.js" as="script"><link rel="prefetch" href="/assets/05.Levels2ReflectiveTextSummary.html-PAa9qFfi.js" as="script"><link rel="prefetch" href="/assets/06.Resources.html-4ueEfsH5.js" as="script"><link rel="prefetch" href="/assets/07.GLOBEM.html-Cev04gBQ.js" as="script"><link rel="prefetch" href="/assets/08.GLOBEMAnalysis.html-D7OhsFg0.js" as="script"><link rel="prefetch" href="/assets/09.ConfirmatoryFactorAnalysis.html-BNAERGP8.js" as="script"><link rel="prefetch" href="/assets/10.dialog-agent.html-BcfeicN9.js" as="script"><link rel="prefetch" href="/assets/11.dialog-agent-setup.html-CffmXMIV.js" as="script"><link rel="prefetch" href="/assets/12.CalculateClaimingTime.html-rphbQQQb.js" as="script"><link rel="prefetch" href="/assets/index.html-5KcfHPMl.js" as="script"><link rel="prefetch" href="/assets/EventRanking.html-CI_k3v_U.js" as="script"><link rel="prefetch" href="/assets/index.html-D1BHrLqx.js" as="script"><link rel="prefetch" href="/assets/EventRanking.html-CN37DCHC.js" as="script"><link rel="prefetch" href="/assets/GenAI_Locally.html-DNALdZjW.js" as="script"><link rel="prefetch" href="/assets/GenerativeAI.html-BuA9mG3r.js" as="script"><link rel="prefetch" href="/assets/GetGoogleDevAPIKey.html-xsXjiI-a.js" as="script"><link rel="prefetch" href="/assets/KeyWordsExtraction.html-B3PGS9XJ.js" as="script"><link rel="prefetch" href="/assets/ProjectInfo.html-C73PyNBl.js" as="script"><link rel="prefetch" href="/assets/index.html-Cq2nmQ87.js" as="script"><link rel="prefetch" href="/assets/Summarization.html-C3VQBj_B.js" as="script"><link rel="prefetch" href="/assets/UI_Service.html-BDDBMCF4.js" as="script"><link rel="prefetch" href="/assets/VectorDatabase.html-BMKo3C7O.js" as="script"><link rel="prefetch" href="/assets/meeting.html-OigMlf4Z.js" as="script"><link rel="prefetch" href="/assets/index.html-DUySEpUc.js" as="script"><link rel="prefetch" href="/assets/manuscript.html-CwTNT8DX.js" as="script"><link rel="prefetch" href="/assets/index.html-B-uNg16v.js" as="script"><link rel="prefetch" href="/assets/libft.html-Biba8w_K.js" as="script"><link rel="prefetch" href="/assets/test_tools.html-C2I9B5SB.js" as="script"><link rel="prefetch" href="/assets/01.install_env.html-Tire5XKV.js" as="script"><link rel="prefetch" href="/assets/index.html-DV6yMfao.js" as="script"><link rel="prefetch" href="/assets/index.html-CG9xERiy.js" as="script"><link rel="prefetch" href="/assets/index.html-CoNhpH4R.js" as="script"><link rel="prefetch" href="/assets/RangeCombination.html-C4pG490r.js" as="script"><link rel="prefetch" href="/assets/ConfirmatoryFactorAnalysis.html-mbOU3dyP.js" as="script"><link rel="prefetch" href="/assets/index.html-tDjplO_-.js" as="script"><link rel="prefetch" href="/assets/distributions.html-Ck5YBegU.js" as="script"><link rel="prefetch" href="/assets/index.html-CPylB67B.js" as="script"><link rel="prefetch" href="/assets/WFD.html-65h3nAV3.js" as="script"><link rel="prefetch" href="/assets/FIB.html-B7KT8FEf.js" as="script"><link rel="prefetch" href="/assets/MCR.html-murGNbAJ.js" as="script"><link rel="prefetch" href="/assets/index.html-BzMrvUkY.js" as="script"><link rel="prefetch" href="/assets/DI-Exercise.html-BMdq_-Xm.js" as="script"><link rel="prefetch" href="/assets/DI.html-DnM59PHU.js" as="script"><link rel="prefetch" href="/assets/RA.html-DqtF7SjM.js" as="script"><link rel="prefetch" href="/assets/index.html-DWnl8BDN.js" as="script"><link rel="prefetch" href="/assets/RL.html-knphUYpg.js" as="script"><link rel="prefetch" href="/assets/index.html-DgNtuGzc.js" as="script"><link rel="prefetch" href="/assets/WE.html-DmepFyVX.js" as="script"><link rel="prefetch" href="/assets/Big Data Concepts.html-eWOpNNO4.js" as="script"><link rel="prefetch" href="/assets/index.html-CrYIPPox.js" as="script"><link rel="prefetch" href="/assets/Relational Databases and Warehouses.html-B4Ak0DJ1.js" as="script"><link rel="prefetch" href="/assets/Statistical Programming for Data Science.html-B_LE2dA3.js" as="script"><link rel="prefetch" href="/assets/Statistics for Data Science.html-B-ypShfP.js" as="script"><link rel="prefetch" href="/assets/Data Visualisation.html-CBbWIyBj.js" as="script"><link rel="prefetch" href="/assets/Predictive Analytics.html-CRLMmrVN.js" as="script"><link rel="prefetch" href="/assets/index.html-Cwf0uY0h.js" as="script"><link rel="prefetch" href="/assets/Research Methods.html-D3nCxqJg.js" as="script"><link rel="prefetch" href="/assets/Unsupervised Methods in Analytics.html-s0gQe6bm.js" as="script"><link rel="prefetch" href="/assets/index.html-BcKQzvvo.js" as="script"><link rel="prefetch" href="/assets/index.html-B6I_Q-Fo.js" as="script"><link rel="prefetch" href="/assets/index.html-KOP0aG2_.js" as="script"><link rel="prefetch" href="/assets/01.ai_models.html-CWyL5CL7.js" as="script"><link rel="prefetch" href="/assets/02.cuda.html-ytvuL2p9.js" as="script"><link rel="prefetch" href="/assets/04.Speech2Text.html-CiHICnv-.js" as="script"><link rel="prefetch" href="/assets/05.fine-tune.html-C2R4TW1a.js" as="script"><link rel="prefetch" href="/assets/06.peft_docs.html-g4paTepD.js" as="script"><link rel="prefetch" href="/assets/07.pytorch_finetune.html-DBudGw3O.js" as="script"><link rel="prefetch" href="/assets/08.OpenVoiceVoiceCloing.html-DhA6tEAr.js" as="script"><link rel="prefetch" href="/assets/09.Videos.html-CTyasRIp.js" as="script"><link rel="prefetch" href="/assets/10.DeepFaceLive.html-DhMg-GSk.js" as="script"><link rel="prefetch" href="/assets/11.FaceRecognizer.html-Bxvk2ZZQ.js" as="script"><link rel="prefetch" href="/assets/12.CreateAnimationVideo.html-DSsaTEIt.js" as="script"><link rel="prefetch" href="/assets/13.NeRF.html-zHmWXFsx.js" as="script"><link rel="prefetch" href="/assets/14.HuggingFace.html-CmCV5h0F.js" as="script"><link rel="prefetch" href="/assets/Gemini.html-CSP-YfNR.js" as="script"><link rel="prefetch" href="/assets/QA.html-Dioe7_KH.js" as="script"><link rel="prefetch" href="/assets/index.html-UxOtYi3s.js" as="script"><link rel="prefetch" href="/assets/RAG.html-Dqui8TzN.js" as="script"><link rel="prefetch" href="/assets/index.html-CJV0N7eD.js" as="script"><link rel="prefetch" href="/assets/index.html-C4L1jDck.js" as="script"><link rel="prefetch" href="/assets/SensitivityReport.html-B6SElyXh.js" as="script"><link rel="prefetch" href="/assets/Solver.html-CxJbqqB2.js" as="script"><link rel="prefetch" href="/assets/MountGoogleDrive.html-CLTw5_XB.js" as="script"><link rel="prefetch" href="/assets/index.html-DoHuy_ZP.js" as="script"><link rel="prefetch" href="/assets/Techniques.html-CWlAVz9h.js" as="script"><link rel="prefetch" href="/assets/00.basic_concept.html-Bc6vbgsL.js" as="script"><link rel="prefetch" href="/assets/index.html-COTek2KH.js" as="script"><link rel="prefetch" href="/assets/index.html-BfFCm4hv.js" as="script"><link rel="prefetch" href="/assets/00.basic_concept.html-CDW7qRyI.js" as="script"><link rel="prefetch" href="/assets/00.docker_diagnosis.html-DhgdR08k.js" as="script"><link rel="prefetch" href="/assets/01.basic_usuage.html-DmUjrxa-.js" as="script"><link rel="prefetch" href="/assets/02.basic_images.html-D0nTWHop.js" as="script"><link rel="prefetch" href="/assets/03.ConnectionOfContainers.html-CU1e8FnM.js" as="script"><link rel="prefetch" href="/assets/04.DockerFile.html-CimTFIlD.js" as="script"><link rel="prefetch" href="/assets/05.DockerFile-Example.html-BTiZbMtr.js" as="script"><link rel="prefetch" href="/assets/06.DockerFile-Network.html-caWeqtMM.js" as="script"><link rel="prefetch" href="/assets/index.html-Cme-8u3x.js" as="script"><link rel="prefetch" href="/assets/RunOS.html-BSetkG-f.js" as="script"><link rel="prefetch" href="/assets/index.html-DKBonq6g.js" as="script"><link rel="prefetch" href="/assets/q_a.html-BDCaRfyJ.js" as="script"><link rel="prefetch" href="/assets/index.html-Dw4p6Rt6.js" as="script"><link rel="prefetch" href="/assets/basic_usage.html-DAIXvuVY.js" as="script"><link rel="prefetch" href="/assets/gitee.html-smHULcx6.js" as="script"><link rel="prefetch" href="/assets/post_site_using_git.html-Dv66Bq3A.js" as="script"><link rel="prefetch" href="/assets/problems.html-BuAzsP33.js" as="script"><link rel="prefetch" href="/assets/01.nginx-version.html-fqiASriY.js" as="script"><link rel="prefetch" href="/assets/02.nginx-basic.html-BNDJZBsB.js" as="script"><link rel="prefetch" href="/assets/03.nginx-advanced.html-RM5rC3xL.js" as="script"><link rel="prefetch" href="/assets/index.html-rRgZEj9f.js" as="script"><link rel="prefetch" href="/assets/proxy.html-BjTRc6xm.js" as="script"><link rel="prefetch" href="/assets/index.html-XwKJ9tQm.js" as="script"><link rel="prefetch" href="/assets/UltraVNC.html-B4sj_SlE.js" as="script"><link rel="prefetch" href="/assets/academic.html-Bds11bJu.js" as="script"><link rel="prefetch" href="/assets/kms.html-BLKRgkJ0.js" as="script"><link rel="prefetch" href="/assets/notion.html-COZt0Gqu.js" as="script"><link rel="prefetch" href="/assets/pdf.html-VUAVSpKF.js" as="script"><link rel="prefetch" href="/assets/ts.html-DknRApqZ.js" as="script"><link rel="prefetch" href="/assets/01.R Language.html-CNGWcLtn.js" as="script"><link rel="prefetch" href="/assets/02.Statistical tests.html-J4QEhF0s.js" as="script"><link rel="prefetch" href="/assets/03.Data manipulation.html-B8fyGL0L.js" as="script"><link rel="prefetch" href="/assets/index.html-84Y9-4Jx.js" as="script"><link rel="prefetch" href="/assets/01.Basic.html-Cu_2OQ1c.js" as="script"><link rel="prefetch" href="/assets/index.html-BlRaMduU.js" as="script"><link rel="prefetch" href="/assets/index.html-BejwxCF4.js" as="script"><link rel="prefetch" href="/assets/libraries.html-C1zu_lq5.js" as="script"><link rel="prefetch" href="/assets/index.html-B31BFx0x.js" as="script"><link rel="prefetch" href="/assets/index.html-Djv4lNyQ.js" as="script"><link rel="prefetch" href="/assets/index.html-BSBRzMbI.js" as="script"><link rel="prefetch" href="/assets/tile_coordinates.html-IFmOVoWI.js" as="script"><link rel="prefetch" href="/assets/wmts.html-Cljbp-nL.js" as="script"><link rel="prefetch" href="/assets/index.html-kAC3a36S.js" as="script"><link rel="prefetch" href="/assets/geonode.html-CTaC2il-.js" as="script"><link rel="prefetch" href="/assets/index.html-CCU7gI7P.js" as="script"><link rel="prefetch" href="/assets/enlarge.html-DFpWmI7t.js" as="script"><link rel="prefetch" href="/assets/gcptowarp.html-CkV4Iq56.js" as="script"><link rel="prefetch" href="/assets/pythonwithgdal.html-Dk8oOuRg.js" as="script"><link rel="prefetch" href="/assets/resources.html-Cg5JW4jT.js" as="script"><link rel="prefetch" href="/assets/vivid_retrive_and_analysis.html-BmCxAk0R.js" as="script"><link rel="prefetch" href="/assets/index.html-C4-Eaguo.js" as="script"><link rel="prefetch" href="/assets/components.html-DzjBJkSR.js" as="script"><link rel="prefetch" href="/assets/external_src.html-agRfWFdG.js" as="script"><link rel="prefetch" href="/assets/01.AF_interventions.html-5Gi49MGw.js" as="script"><link rel="prefetch" href="/assets/index.html-BnMW_DSm.js" as="script"><link rel="prefetch" href="/assets/01.LinearRegressionAnalysis.html-CtxKOmYS.js" as="script"><link rel="prefetch" href="/assets/02.Bounds.html-E4O--f8I.js" as="script"><link rel="prefetch" href="/assets/02.Forcasting.html-CJC1J-sh.js" as="script"><link rel="prefetch" href="/assets/02.TimeSeriesAnalysis.html-BJOpLb4v.js" as="script"><link rel="prefetch" href="/assets/03.TimeSeriesAnalysis(SlidesOf Jhon).html-Bckffhmp.js" as="script"><link rel="prefetch" href="/assets/AdvancedAnalyticTechniques1.html-DqyoZqdX.js" as="script"><link rel="prefetch" href="/assets/Arch_GArchPractical.html-bxEJodpo.js" as="script"><link rel="prefetch" href="/assets/ContinueAssessments.html-Cib6xK6p.js" as="script"><link rel="prefetch" href="/assets/index.html-lFsDglaf.js" as="script"><link rel="prefetch" href="/assets/SyntheticPractical.html-C_4baVK2.js" as="script"><link rel="prefetch" href="/assets/Week6Practice.html-ZgWz73se.js" as="script"><link rel="prefetch" href="/assets/WeeklyPractice.html-CG0i5A0P.js" as="script"><link rel="prefetch" href="/assets/assignment1.html-CBd54QNf.js" as="script"><link rel="prefetch" href="/assets/assignment2.html-BgrSFvur.js" as="script"><link rel="prefetch" href="/assets/project.html-DRXd7caw.js" as="script"><link rel="prefetch" href="/assets/project_discard.html-80mbt3Sp.js" as="script"><link rel="prefetch" href="/assets/requirements_assignment1.html-qRJH0vU-.js" as="script"><link rel="prefetch" href="/assets/requirements_assignment2.html-gi2hjU7g.js" as="script"><link rel="prefetch" href="/assets/requirements_proj.html-CUGDeooM.js" as="script"><link rel="prefetch" href="/assets/01.NaiveBayes.html-EOziTRrC.js" as="script"><link rel="prefetch" href="/assets/02.Bayesian Networks(Week3).html-qfNacLg7.js" as="script"><link rel="prefetch" href="/assets/03.Bayesian Networks(Week4).html-CuGMovFj.js" as="script"><link rel="prefetch" href="/assets/04.Bayesian Networks(Week5).html-D1XewpK9.js" as="script"><link rel="prefetch" href="/assets/05.Text Mining(Week6).html-xmYXwFee.js" as="script"><link rel="prefetch" href="/assets/06.Data Stream(Week7).html-By7BK6rY.js" as="script"><link rel="prefetch" href="/assets/07.Geospatial.html-C1gBhMYV.js" as="script"><link rel="prefetch" href="/assets/index.html-C-KpIndu.js" as="script"><link rel="prefetch" href="/assets/Requirements_Project.html-BhwgWYk3.js" as="script"><link rel="prefetch" href="/assets/Requirements_assignment1.html-DXmOULO_.js" as="script"><link rel="prefetch" href="/assets/Requirements_assignment2.html-D6zKkJJG.js" as="script"><link rel="prefetch" href="/assets/assignment1.html-Bzmy8nNA.js" as="script"><link rel="prefetch" href="/assets/assignment2.html-DjfaOhwG.js" as="script"><link rel="prefetch" href="/assets/practices.01.html-r_7PrTgs.js" as="script"><link rel="prefetch" href="/assets/practices.02.html-X49Q5W4j.js" as="script"><link rel="prefetch" href="/assets/practices.03.html-DW4qeZFy.js" as="script"><link rel="prefetch" href="/assets/practices.04.html-Dsxd2e1w.js" as="script"><link rel="prefetch" href="/assets/project.html-CgCkYBrV.js" as="script"><link rel="prefetch" href="/assets/01.index.html-CZwAyKxO.js" as="script"><link rel="prefetch" href="/assets/02.TaskSteps.html-Ca8Dq7nU.js" as="script"><link rel="prefetch" href="/assets/Data Science Professional Development.html-DOtZMej5.js" as="script"><link rel="prefetch" href="/assets/index.html-clmr7Gm7.js" as="script"><link rel="prefetch" href="/assets/01.Resources.html-B2bpOih8.js" as="script"><link rel="prefetch" href="/assets/FinalReportPresentation.html-DzYh2H9T.js" as="script"><link rel="prefetch" href="/assets/ProjectDescription.html-1CBIFRyo.js" as="script"><link rel="prefetch" href="/assets/ProjectPlan.html-BbfYsel_.js" as="script"><link rel="prefetch" href="/assets/ProjectPlanPresentation.html-D3GQhfYl.js" as="script"><link rel="prefetch" href="/assets/index.html-B71SBBBM.js" as="script"><link rel="prefetch" href="/assets/Assignment1.html-BvzoWo8n.js" as="script"><link rel="prefetch" href="/assets/Assignment2.1.html-B1an6BJ0.js" as="script"><link rel="prefetch" href="/assets/Assignment2.2.html-Bt_l5tFZ.js" as="script"><link rel="prefetch" href="/assets/Exercise1.html-Cshdimal.js" as="script"><link rel="prefetch" href="/assets/Exercise2.html-ugTzfrjH.js" as="script"><link rel="prefetch" href="/assets/index.html-Czg-kFOi.js" as="script"><link rel="prefetch" href="/assets/Week1.html-Du6O_1RT.js" as="script"><link rel="prefetch" href="/assets/Week2.html-_12xDGkq.js" as="script"><link rel="prefetch" href="/assets/Week3.html-OiqGYxTZ.js" as="script"><link rel="prefetch" href="/assets/Week4.html-CdiRoX-l.js" as="script"><link rel="prefetch" href="/assets/Week5.html-MMOcWUlx.js" as="script"><link rel="prefetch" href="/assets/Week7.html-DWEN4ZkR.js" as="script"><link rel="prefetch" href="/assets/Week9.html-CeTJLiJt.js" as="script"><link rel="prefetch" href="/assets/Assessment2.1.html-BAl71qRw.js" as="script"><link rel="prefetch" href="/assets/Assessment2.2.html-CgsEZl88.js" as="script"><link rel="prefetch" href="/assets/index.html-BRCSwbH-.js" as="script"><link rel="prefetch" href="/assets/continuousAssessment1.1.html-B2BrxX9q.js" as="script"><link rel="prefetch" href="/assets/continuousAssessment1.2.html-BmN3B3oW.js" as="script"><link rel="prefetch" href="/assets/01.kmeans.html-CnlFw3Tg.js" as="script"><link rel="prefetch" href="/assets/index.html-CY14FPfq.js" as="script"><link rel="prefetch" href="/assets/index.html-CjHvTpxL.js" as="script"><link rel="prefetch" href="/assets/basic.html-D6yIlYm3.js" as="script"><link rel="prefetch" href="/assets/finetuning.html-Bwt8AzQ2.js" as="script"><link rel="prefetch" href="/assets/index.html-DiC9Ov-W.js" as="script"><link rel="prefetch" href="/assets/droidcam.html-BJnhefRZ.js" as="script"><link rel="prefetch" href="/assets/res.html-C5rKMrxR.js" as="script"><link rel="prefetch" href="/assets/vlc_rtsp.html-CNH7Oq4y.js" as="script"><link rel="prefetch" href="/assets/01.index.html-BHl5rs7n.js" as="script"><link rel="prefetch" href="/assets/02.Common_conf.html-BPpCbS9H.js" as="script"><link rel="prefetch" href="/assets/03.Examples.html-BXaJ5maC.js" as="script"><link rel="prefetch" href="/assets/04.Interceptor.html-DXNvmsNF.js" as="script"><link rel="prefetch" href="/assets/index.html-BdbtJ1Kj.js" as="script"><link rel="prefetch" href="/assets/01.index.html-zyVl5OrH.js" as="script"><link rel="prefetch" href="/assets/02.selector.html-B8NVB4Ym.js" as="script"><link rel="prefetch" href="/assets/03.StyleCharacteristics.html-Dwkq2yw0.js" as="script"><link rel="prefetch" href="/assets/04.TextProperties.html-OtS8aNmK.js" as="script"><link rel="prefetch" href="/assets/04.Units.html-DxRceHOc.js" as="script"><link rel="prefetch" href="/assets/05.DocumentFlow.html-BVZvl2_k.js" as="script"><link rel="prefetch" href="/assets/05.Eelements.html-7y4dzjNN.js" as="script"><link rel="prefetch" href="/assets/06.div.html-BjfxEgwI.js" as="script"><link rel="prefetch" href="/assets/07.float.html-BN3yfpWl.js" as="script"><link rel="prefetch" href="/assets/08.flex.html-CTP2_SSf.js" as="script"><link rel="prefetch" href="/assets/09.Position.html-D16hDpdu.js" as="script"><link rel="prefetch" href="/assets/10.Font_Background.html-DUfQDHsZ.js" as="script"><link rel="prefetch" href="/assets/11.Table_Form.html-CY2gCQBC.js" as="script"><link rel="prefetch" href="/assets/12.Animation.html-BY3qjjIq.js" as="script"><link rel="prefetch" href="/assets/index.html-VbohL5jj.js" as="script"><link rel="prefetch" href="/assets/html_editor.html-C9burhD9.js" as="script"><link rel="prefetch" href="/assets/index.html-BVLQpU78.js" as="script"><link rel="prefetch" href="/assets/html.html-BRkdtMsa.js" as="script"><link rel="prefetch" href="/assets/html_Semantic.html-BHUCDkTa.js" as="script"><link rel="prefetch" href="/assets/html_element_type.html-B6xiOxsQ.js" as="script"><link rel="prefetch" href="/assets/html_statement.html-CgGjfIaO.js" as="script"><link rel="prefetch" href="/assets/01.index.html-C7rx7w9u.js" as="script"><link rel="prefetch" href="/assets/02.instructor.html-CBsOMnUS.js" as="script"><link rel="prefetch" href="/assets/03.ComputedAttributes.html-3fKMhhSb.js" as="script"><link rel="prefetch" href="/assets/04.filter.html-3RVHhgw_.js" as="script"><link rel="prefetch" href="/assets/05.LifeCycleEvents.html-BNaoUOzf.js" as="script"><link rel="prefetch" href="/assets/06.Components.html-C-sU-PCn.js" as="script"><link rel="prefetch" href="/assets/07.Plugins.html-Btq4khYL.js" as="script"><link rel="prefetch" href="/assets/index.html-BqaN-FWR.js" as="script"><link rel="prefetch" href="/assets/01.index.html-DZbvGnNV.js" as="script"><link rel="prefetch" href="/assets/index.html-hn1CbqGt.js" as="script"><link rel="prefetch" href="/assets/index.html-FMk-14MY.js" as="script"><link rel="prefetch" href="/assets/async_basic.html-CkU7EWsx.js" as="script"><link rel="prefetch" href="/assets/GenCorrelatedData.html-DFTcvLGI.js" as="script"><link rel="prefetch" href="/assets/Numpy.html-BDfpFo9E.js" as="script"><link rel="prefetch" href="/assets/Pandas.html-DTUw7W_9.js" as="script"><link rel="prefetch" href="/assets/index.html-CNzm1Vet.js" as="script"><link rel="prefetch" href="/assets/index.html-CurmwNu1.js" as="script"><link rel="prefetch" href="/assets/SeniorFunction.html-MRaPDd7m.js" as="script"><link rel="prefetch" href="/assets/SingleClass.html-DtOdD81Z.js" as="script"><link rel="prefetch" href="/assets/VirtualEnvironment.html-DT7cboL9.js" as="script"><link rel="prefetch" href="/assets/csv.html-V-pZwTHV.js" as="script"><link rel="prefetch" href="/assets/env.html-D9enF7y0.js" as="script"><link rel="prefetch" href="/assets/fmd5.html-C-75FBW7.js" as="script"><link rel="prefetch" href="/assets/jupyter.html-RoTxO5qj.js" as="script"><link rel="prefetch" href="/assets/logging.html-D0dNWOIE.js" as="script"><link rel="prefetch" href="/assets/pip.html-Bwn6J8fY.js" as="script"><link rel="prefetch" href="/assets/pyinstaller.html-BG9heJyo.js" as="script"><link rel="prefetch" href="/assets/thread.html-BqrX6Fx6.js" as="script"><link rel="prefetch" href="/assets/index.html-DFhXw5Ke.js" as="script"><link rel="prefetch" href="/assets/psql_conn_pool.html-Dx9xMCYI.js" as="script"><link rel="prefetch" href="/assets/index.html-DB1lhPQx.js" as="script"><link rel="prefetch" href="/assets/scan_load.html-DS0VS7f9.js" as="script"><link rel="prefetch" href="/assets/index.html-DtgoO4NG.js" as="script"><link rel="prefetch" href="/assets/bs4.html-Bu3XfJNp.js" as="script"><link rel="prefetch" href="/assets/fastapi.html-BQVOf7kX.js" as="script"><link rel="prefetch" href="/assets/http.html-L5oArJIs.js" as="script"><link rel="prefetch" href="/assets/404.html-CAC1eWnk.js" as="script"><link rel="prefetch" href="/assets/index.html-ByVeAA2I.js" as="script"><link rel="prefetch" href="/assets/index.html-D736yFQF.js" as="script"><link rel="prefetch" href="/assets/index.html-CvP6ULg-.js" as="script"><link rel="prefetch" href="/assets/index.html-D01sLb7k.js" as="script"><link rel="prefetch" href="/assets/index.html-CHlzKWMw.js" as="script"><link rel="prefetch" href="/assets/index.html-D-0SyAsw.js" as="script"><link rel="prefetch" href="/assets/index.html-Bu5sZrus.js" as="script"><link rel="prefetch" href="/assets/index.html-k8bIIATU.js" as="script"><link rel="prefetch" href="/assets/index.html-DUIIUNo1.js" as="script"><link rel="prefetch" href="/assets/index.html-BiapGoF2.js" as="script"><link rel="prefetch" href="/assets/index.html-DqpuP0Qm.js" as="script"><link rel="prefetch" href="/assets/index.html-9NKLa-4Q.js" as="script"><link rel="prefetch" href="/assets/index.html-CQIMoMBG.js" as="script"><link rel="prefetch" href="/assets/index.html-CSZySiC6.js" as="script"><link rel="prefetch" href="/assets/index.html-B7YhWGQ_.js" as="script"><link rel="prefetch" href="/assets/index.html-C3bdBnJH.js" as="script"><link rel="prefetch" href="/assets/index.html-Dlmg58Gd.js" as="script"><link rel="prefetch" href="/assets/index.html-Do1Ux3oK.js" as="script"><link rel="prefetch" href="/assets/index.html-DsGLrb6O.js" as="script"><link rel="prefetch" href="/assets/index.html-LcSLnAEz.js" as="script"><link rel="prefetch" href="/assets/index.html-Jp7TDlWs.js" as="script"><link rel="prefetch" href="/assets/index.html-Dep7gWD8.js" as="script"><link rel="prefetch" href="/assets/index.html-Bo2W7yLr.js" as="script"><link rel="prefetch" href="/assets/index.html-D920A9O-.js" as="script"><link rel="prefetch" href="/assets/index.html-B5fUdNEH.js" as="script"><link rel="prefetch" href="/assets/index.html-DEaH3F0E.js" as="script"><link rel="prefetch" href="/assets/index.html-d8zbqzNT.js" as="script"><link rel="prefetch" href="/assets/index.html-Bp4uT5jD.js" as="script"><link rel="prefetch" href="/assets/index.html-CZMcbnIy.js" as="script"><link rel="prefetch" href="/assets/index.html-D913RV1Z.js" as="script"><link rel="prefetch" href="/assets/index.html-Cn_R2Fdv.js" as="script"><link rel="prefetch" href="/assets/index.html-DrbV9Ydw.js" as="script"><link rel="prefetch" href="/assets/index.html-B01BZqXm.js" as="script"><link rel="prefetch" href="/assets/index.html-7cfSh8cA.js" as="script"><link rel="prefetch" href="/assets/index.html-BaLKf4q4.js" as="script"><link rel="prefetch" href="/assets/index.html-D7arOxZR.js" as="script"><link rel="prefetch" href="/assets/index.html-CVqh1CAa.js" as="script"><link rel="prefetch" href="/assets/index.html-XM5_zjS3.js" as="script"><link rel="prefetch" href="/assets/index.html-Caztv-45.js" as="script"><link rel="prefetch" href="/assets/index.html-BI2rSXpY.js" as="script"><link rel="prefetch" href="/assets/index.html-BJnAZWFg.js" as="script"><link rel="prefetch" href="/assets/index.html-Gr1x94r9.js" as="script"><link rel="prefetch" href="/assets/index.html-eohEW59J.js" as="script"><link rel="prefetch" href="/assets/index.html-CiGS1PTl.js" as="script"><link rel="prefetch" href="/assets/index.html-ABQX6ml7.js" as="script"><link rel="prefetch" href="/assets/index.html-fv6xOBVu.js" as="script"><link rel="prefetch" href="/assets/index.html-BXkMq6eM.js" as="script"><link rel="prefetch" href="/assets/index.html-0uUGFSHz.js" as="script"><link rel="prefetch" href="/assets/index.html-CdCXYj48.js" as="script"><link rel="prefetch" href="/assets/index.html-fJXoBydD.js" as="script"><link rel="prefetch" href="/assets/index.html-D8yhGp4-.js" as="script"><link rel="prefetch" href="/assets/index.html-DZR5cWag.js" as="script"><link rel="prefetch" href="/assets/index.html-Bpzl7915.js" as="script"><link rel="prefetch" href="/assets/index.html-Cg_Kjnoa.js" as="script"><link rel="prefetch" href="/assets/index.html-q3WkWgMz.js" as="script"><link rel="prefetch" href="/assets/index.html-BOZQViyN.js" as="script"><link rel="prefetch" href="/assets/index.html-DOC7sn_u.js" as="script"><link rel="prefetch" href="/assets/index.html-BplBV8xy.js" as="script"><link rel="prefetch" href="/assets/index.html-DV4GSF7-.js" as="script"><link rel="prefetch" href="/assets/index.html-ChDgZW_e.js" as="script"><link rel="prefetch" href="/assets/index.html-C4bmjxHg.js" as="script"><link rel="prefetch" href="/assets/index.html-HZRCcA0Y.js" as="script"><link rel="prefetch" href="/assets/index.html-Dxz_zMXb.js" as="script"><link rel="prefetch" href="/assets/index.html-Ruq7-3_K.js" as="script"><link rel="prefetch" href="/assets/index.html-Dk1jkvbp.js" as="script"><link rel="prefetch" href="/assets/index.html-LnTE66Qv.js" as="script"><link rel="prefetch" href="/assets/index.html-BdPiB-QC.js" as="script"><link rel="prefetch" href="/assets/index.html-D47Pcaak.js" as="script"><link rel="prefetch" href="/assets/index.html-Dk7zYynU.js" as="script"><link rel="prefetch" href="/assets/index.html-CxXddDQi.js" as="script"><link rel="prefetch" href="/assets/index.html-BbHqm5gN.js" as="script"><link rel="prefetch" href="/assets/index.html-592Kj_Jp.js" as="script"><link rel="prefetch" href="/assets/index.html-Dz3syxOM.js" as="script"><link rel="prefetch" href="/assets/index.html-kBoLgVWc.js" as="script"><link rel="prefetch" href="/assets/index.html-B8SzMQJv.js" as="script"><link rel="prefetch" href="/assets/index.html-eViwbz0C.js" as="script"><link rel="prefetch" href="/assets/index.html-Cmr6rRDH.js" as="script"><link rel="prefetch" href="/assets/index.html-BAo_tbqd.js" as="script"><link rel="prefetch" href="/assets/index.html-9q5aW025.js" as="script"><link rel="prefetch" href="/assets/index.html-DKkQm6f2.js" as="script"><link rel="prefetch" href="/assets/index.html-70ufuLPZ.js" as="script"><link rel="prefetch" href="/assets/index.html-Ci5_aNqC.js" as="script"><link rel="prefetch" href="/assets/index.html-sOf0nOyc.js" as="script"><link rel="prefetch" href="/assets/index.html-DMlYM2aw.js" as="script"><link rel="prefetch" href="/assets/index.html-B7CiRMdn.js" as="script"><link rel="prefetch" href="/assets/index.html-DellLo2x.js" as="script"><link rel="prefetch" href="/assets/index.html-Cfjvv03L.js" as="script"><link rel="prefetch" href="/assets/index.html-BjmjKy9N.js" as="script"><link rel="prefetch" href="/assets/index.html-lIB62Vdb.js" as="script"><link rel="prefetch" href="/assets/index.html-BejBBwCc.js" as="script"><link rel="prefetch" href="/assets/index.html-CqkCqOxK.js" as="script"><link rel="prefetch" href="/assets/index.html-DOFFZCn9.js" as="script"><link rel="prefetch" href="/assets/index.html-DUWPa0mX.js" as="script"><link rel="prefetch" href="/assets/index.html-BJxij6et.js" as="script"><link rel="prefetch" href="/assets/index.html-DbsFGOU3.js" as="script"><link rel="prefetch" href="/assets/index.html-BWOE6EXS.js" as="script"><link rel="prefetch" href="/assets/index.html-DwEI9IcT.js" as="script"><link rel="prefetch" href="/assets/index.html-BcXqjA5X.js" as="script"><link rel="prefetch" href="/assets/index.html-CR092WGF.js" as="script"><link rel="prefetch" href="/assets/index.html-BbjKj2f5.js" as="script"><link rel="prefetch" href="/assets/index.html-BO0-CDA-.js" as="script"><link rel="prefetch" href="/assets/index.html-DIfxQbUq.js" as="script"><link rel="prefetch" href="/assets/index.html-DVk0daux.js" as="script"><link rel="prefetch" href="/assets/index.html-BtvvouOP.js" as="script"><link rel="prefetch" href="/assets/index.html-zDYKoMtM.js" as="script"><link rel="prefetch" href="/assets/index.html-xWHlvPAJ.js" as="script"><link rel="prefetch" href="/assets/index.html-I3FgmAj-.js" as="script"><link rel="prefetch" href="/assets/index.html-CpOI4Z5X.js" as="script"><link rel="prefetch" href="/assets/index.html-Cgqa3_SV.js" as="script"><link rel="prefetch" href="/assets/index.html-BM3zZlIN.js" as="script"><link rel="prefetch" href="/assets/index.html-DIQg6xGc.js" as="script"><link rel="prefetch" href="/assets/index.html-BthwXwJP.js" as="script"><link rel="prefetch" href="/assets/index.html-B7oFUzFn.js" as="script"><link rel="prefetch" href="/assets/index.html-BqSARclu.js" as="script"><link rel="prefetch" href="/assets/index.html-BjsBElv4.js" as="script"><link rel="prefetch" href="/assets/index.html-CC6Hk2Gg.js" as="script"><link rel="prefetch" href="/assets/index.html-CmuRGi6N.js" as="script"><link rel="prefetch" href="/assets/auto-Cl2ltNcc.js" as="script"><link rel="prefetch" href="/assets/index-AN989yVn.js" as="script"><link rel="prefetch" href="/assets/flowchart-CTwbLKUk.js" as="script"><link rel="prefetch" href="/assets/mermaid.esm.min-U1QQYtrK.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-GXRgw7eJ.js" as="script"><link rel="prefetch" href="/assets/SearchResult-GUXh5ro5.js" as="script"><link rel="prefetch" href="/assets/reveal.esm-B3O8JSaZ.js" as="script"><link rel="prefetch" href="/assets/markdown.esm-BcQCyT6L.js" as="script"><link rel="prefetch" href="/assets/highlight.esm-C34tS8ua.js" as="script"><link rel="prefetch" href="/assets/math.esm-DN7Rh_EM.js" as="script"><link rel="prefetch" href="/assets/search.esm-DuBqnxcF.js" as="script"><link rel="prefetch" href="/assets/notes.esm-YR_UvoMg.js" as="script"><link rel="prefetch" href="/assets/zoom.esm-Ctj_eavO.js" as="script"><link rel="prefetch" href="/assets/setupDevtools-7MC2TMWH-B9HOPLvu.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/" aria-label="Take me home"><img class="vp-nav-logo" src="/haiyue.jpg" alt><!----><span class="vp-site-name hide-in-pad">Haiyue&#39;s Blog</span></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="Blog Home"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span><!--]-->Blog Home<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/techniques/" aria-label="Techniques"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><!--]-->Techniques<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/study/" aria-label="Study"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><!--]-->Study<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/work/" aria-label="Work"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><!--]-->Work<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/models/" aria-label="Models"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><!--]-->Models<!----></a></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><!----><!----><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--[--><button type="button" class="search-pro-button" aria-label="Search"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon" name="search"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">Search</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><span class="vp-sidebar-title">AI Related</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><span class="vp-sidebar-title">Basic Concept</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><span class="vp-sidebar-title">Others</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/techniques/AI/Others/09.Videos.html" aria-label="AI for Videos"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->AI for Videos<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/techniques/AI/Others/01.ai_models.html" aria-label="AI Models List"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->AI Models List<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/techniques/AI/Others/Gemini.html" aria-label="API usuage"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->API usuage<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/techniques/AI/Others/03.DeepSpeech2Text.html" aria-label="Audio to Text (DeepSpeech)"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->Audio to Text (DeepSpeech)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/techniques/AI/Others/04.Speech2Text.html" aria-label="Audio to Text (OpenAI)"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->Audio to Text (OpenAI)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/techniques/AI/Others/02.cuda.html" aria-label="CUDA Torch"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->CUDA Torch<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/techniques/AI/Others/11.FaceRecognizer.html" aria-label="Face Recognizer using Python"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->Face Recognizer using Python<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/techniques/AI/Others/12.CreateAnimationVideo.html" aria-label="Face Recognizer using Python"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->Face Recognizer using Python<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/techniques/AI/Others/13.NeRF.html" aria-label="Face Recognizer using Python"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->Face Recognizer using Python<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/techniques/AI/Others/07.pytorch_finetune.html" aria-label="Fine Tune Models"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->Fine Tune Models<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/techniques/AI/Others/05.fine-tune.html" aria-label="Fine-tune for Models"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->Fine-tune for Models<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/techniques/AI/Others/14.HuggingFace.html" aria-label="HuggingFace"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->HuggingFace<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/techniques/AI/Others/10.DeepFaceLive.html" aria-label="Install DeepFaceLive on Windows"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->Install DeepFaceLive on Windows<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><span class="vp-sidebar-title">OpenAI</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/techniques/AI/Others/08.OpenVoiceVoiceCloing.html" aria-label="OpenVoice Voice Cloning"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->OpenVoice Voice Cloning<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/techniques/AI/Others/06.peft_docs.html" aria-label="Peft docs"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->Peft docs<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/techniques/AI/Others/QA.html" aria-label="QA"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span><!--]-->QA<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><span class="vp-sidebar-title">RAG</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><span class="vp-sidebar-title">AWS</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><span class="vp-sidebar-title">Coding</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><span class="vp-sidebar-title">Geoscience</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><span class="vp-sidebar-title">Media</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><span class="vp-sidebar-title">Streamlit</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><span class="vp-sidebar-title">Tools</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><span class="vp-sidebar-title">Ubuntu Related</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><span class="vp-sidebar-title">Vuepress</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><span class="vp-sidebar-title">WeChat</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-list-check" style=""></span><span class="vp-sidebar-title">WSL</span><span class="vp-arrow end"></span></button><!----></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span>Audio to Text (DeepSpeech)</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Haiyue</span></span><span property="author" content="Haiyue"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">November 27, 2023</span><meta property="datePublished" content="2023-11-27T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 8 min</span><meta property="timeRequired" content="PT8M"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color5 clickable" role="navigation">AI</span><!--]--><meta property="articleSection" content="AI"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color2 clickable" role="navigation">audio2text</span><!--]--><meta property="keywords" content="audio2text"></span></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!----><div class="vp-toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#what-is-deepspeech">What is DeepSpeech</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#local-speech-to-text">Local Speech to Text</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#wav-handler">WAV Handler</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#transcribe-speech-to-text">Transcribe Speech to Text</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#reading-arguments-for-deepspeech-speech-to-text">Reading Arguments for DeepSpeech Speech to Text</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#using-deepspeech-for-real-time-or-asynchronous-speech-recognition">Using DeepSpeech for Real Time or Asynchronous Speech Recognition</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#resource">Resource</a></li><!----><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content" vp-content><h2 id="what-is-deepspeech" tabindex="-1"><a class="header-anchor" href="#what-is-deepspeech"><span>What is DeepSpeech</span></a></h2><p>DeepSpeech is an open source Python library that enables us to build automatic speech ecognition systems. It is based on Baidu’s 2014 paper titled <a href="https://arxiv.org/abs/1412.5567" target="_blank" rel="noopener noreferrer">Deep Speech: Scaling up end-to-end speech recognition</a>.</p><h2 id="local-speech-to-text" tabindex="-1"><a class="header-anchor" href="#local-speech-to-text"><span>Local Speech to Text</span></a></h2><p>The libraries are needed.</p><ol><li><code>deepspeech</code></li><li><code>numpy</code></li><li><code>webrtcvad</code>: voice activity detection (VAD) library developed by Google for WebRTC (real time communication).<br> To install all the libraries using the command</li></ol><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> deepspeech</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> numpy</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> webrtcvad</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>For the asynchronous transcription, three files are needed, which are</p><ol><li>One file to handle interaction with WAV data</li><li>one file to transcribe speech to text on a WAV file,</li><li>one to use these two in the command line<br> And also the pretrained DeepSpeech model and scorer are needed.<br> To download the files using the commands</li></ol><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">wget</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">wget</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="wav-handler" tabindex="-1"><a class="header-anchor" href="#wav-handler"><span>WAV Handler</span></a></h3><p><code>wav_handler.py</code></p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> collections</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> contextlib</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wave</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Reading Audio Data from a WAV file</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;Reads a .wav file.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Input: path to a .wav file</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Output: tuple of pcm data, sample rate, and duration</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> read_wave</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">path</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    Let’s start with creating a function to read WAV files. This function will take an input,  this input is the path to a WAV file. The file will use the contextlib library to open the  WAV file and read in the contents as bytes. Next, we run multiple asserts on the WAV file -  it must have one channel, have a sample width of 2, have a sample rate of 8, 16, or 32 kHz.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    Once we have asserted that the WAV file is in the right format for processing, we extract the  frames. Next, we extract the pcm data from the frames and the duration from the metadata.  Finally, we return the PCM data, the sample rate, and the duration.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    with</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> contextlib.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">closing</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(wave.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">open</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(path, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;rb&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wf:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        num_channels </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wf.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">getnchannels</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        assert</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> num_channels </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">==</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        sample_width </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wf.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">getsampwidth</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        assert</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> sample_width </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">==</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 2</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        sample_rate </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wf.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">getframerate</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        assert</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> sample_rate </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">8000</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">16000</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">32000</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        frames </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wf.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">getnframes</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        pcm_data </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wf.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">readframes</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(frames)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        duration </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> frames </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">/</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> sample_rate</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pcm_data, sample_rate, duration</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Writing Audio Data to a WAV file</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;Writes a .wav file.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Input: path to new .wav file, PCM audio data, and sample rate.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Output: a .wav file</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> write_wave</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">path</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> audio</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> sample_rate</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    Now let’s create the function to write audio data to a WAV file. This function requires three parameters, the path to a file to write to, the audio data, and the sample rate. This function writes a WAV file in the same way that the read function asserts its parameters. All we do is here is set the channels, sample width, and frame rate and then write the audio frames.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    with</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> contextlib.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">closing</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(wave.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">open</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(path, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;wb&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wf:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        wf.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">setnchannels</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        wf.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">setsampwidth</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        wf.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">setframerate</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(sample_rate)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        wf.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">writeframes</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(audio)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;Represents a &quot;frame&quot; of audio data.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Requires the number of byes, the timestamp of the frame, and the duration on init&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">class</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;"> Frame</span><span style="--shiki-light:#C18401;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">object</span><span style="--shiki-light:#C18401;--shiki-dark:#ABB2BF;">)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    We’re going to create a class called Frame to hold some information to represent our audio data and make it easier to handle. This object requires three parameters to be created: the bytes, the timestamp in the audio file, and the duration of the Frame.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    def</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> __init__</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E5C07B;--shiki-dark-font-style:italic;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> bytes</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> timestamp</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> duration</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.bytes </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> bytes</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.timestamp </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> timestamp</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.duration </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> duration</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Creating Frames of Audio Data for DeepSpeech to Transcribe</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;Generates audio frames from PCM audio data.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Input: the desired frame duration in milliseconds, the PCM data, and</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">the sample rate.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Yields/Generates: Frames of the requested duration.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> frame_generator</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">frame_duration_ms</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> audio</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> sample_rate</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    this function as a frame generator or a frame factory that returns an iterator. This function requires three parameters: the frame duration in milliseconds, the audio data, and the sample rate.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    </span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    This function starts by deriving an interval of frames from the passed in sample rate and frame duration in milliseconds. We start at an offset and timestamp of 0. We also create a duration constant equal to the number of frames in a second.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    </span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    While the current offset can be incremented by the interval constant and be within the number of frames of the audio, we generate a Frame for each interval and then increment the timestamp and offset appropriately.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    n </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> int</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(sample_rate </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">*</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (frame_duration_ms </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">/</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1000.0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">*</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    offset </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 0</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    timestamp </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 0.0</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    duration </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">float</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(n) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">/</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> sample_rate) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">/</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 2.0</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    while</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> offset </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> n </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&lt;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(audio):</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        yield</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> Frame</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(audio[offset:offset </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> n], timestamp, duration)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        timestamp </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> duration</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        offset </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> n</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Collecting Voice Activated Frames for Speech to Text with DeepSpeech</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;Filters out non-voiced audio frames.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Given a webrtcvad.Vad and a source of audio frames, yields only</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">the voiced audio.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Arguments:</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">sample_rate - The audio sample rate, in Hz.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">frame_duration_ms - The frame duration in milliseconds.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">padding_duration_ms - The amount to pad the window, in milliseconds.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">vad - An instance of webrtcvad.Vad.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">frames - a source of audio frames (sequence or generator).</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Returns: A generator that yields PCM audio data.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> vad_collector</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">sample_rate</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> frame_duration_ms</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">                  padding_duration_ms</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> vad</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> frames</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    function to collect all the frames that contain voice. This function requires a sample rate, the frame duration in milliseconds, the padding duration in milliseconds, a voice activation detector (VAD) from webrtcvad, and the audio data frames.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    The VAD algorithm uses a padded ring buffer and checks to see what percentage of the frames in the window are voiced. When the window reaches a 90% voiced frame rate, the VAD triggers and begins yielding audio frames. While generating frames, if the percentage of voiced audio data in the frame drops below 10%, it will stop generating frames.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    num_padding_frames </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> int</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(padding_duration_ms </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">/</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> frame_duration_ms)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # We use a deque for our sliding window/ring buffer.</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    ring_buffer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> collections.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">deque</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">maxlen</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">num_padding_frames)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # We have two states: TRIGGERED and NOTTRIGGERED. We start in the</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # NOTTRIGGERED state.</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    triggered </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> False</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    voiced_frames </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> frame </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> frames:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        is_speech </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> vad.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">is_speech</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(frame.bytes, sample_rate)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        if</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> not</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> triggered:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            ring_buffer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">((frame, is_speech))</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            num_voiced </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">([f </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> f, speech </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ring_buffer </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> speech])</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            # If we&#39;re NOTTRIGGERED and more than 90% of the frames in</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            # the ring buffer are voiced frames, then enter the</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            # TRIGGERED state.</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">            if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> num_voiced </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&gt;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 0.9</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> *</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ring_buffer.maxlen:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                triggered </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> True</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">                # We want to yield all the audio we see from now until</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">                # we are NOTTRIGGERED, but we have to start with the</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">                # audio that&#39;s already in the ring buffer.</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">                for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> f, s </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ring_buffer:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                    voiced_frames.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(f)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                ring_buffer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">clear</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        else</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            # We&#39;re in the TRIGGERED state, so collect the audio data</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            # and add it to the ring buffer.</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            voiced_frames.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(frame)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            ring_buffer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">((frame, is_speech))</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            num_unvoiced </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">([f </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> f, speech </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ring_buffer </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> not</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> speech])</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            # If more than 90% of the frames in the ring buffer are</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            # unvoiced, then enter NOTTRIGGERED and yield whatever</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            # audio we&#39;ve collected.</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">            if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> num_unvoiced </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&gt;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 0.9</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> *</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ring_buffer.maxlen:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                triggered </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> False</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">                yield</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> b</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">([f.bytes </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> f </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> voiced_frames])</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                ring_buffer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">clear</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                voiced_frames </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> triggered:</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        pass</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # If we have any leftover voiced audio when we run out of input,</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # yield it.</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> voiced_frames:</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        yield</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> b</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">([f.bytes </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> f </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> voiced_frames])</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="transcribe-speech-to-text" tabindex="-1"><a class="header-anchor" href="#transcribe-speech-to-text"><span>Transcribe Speech to Text</span></a></h3><p><code>wav_transcriber.py</code></p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> glob</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> webrtcvad</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> logging</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wav_handler</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> deepspeech </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Model</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> timeit </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> default_timer </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> timer</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Pick Which DeepSpeech Model to Use</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Load the pre-trained model into the memory</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">@param models: Output Graph Protocol Buffer file</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">@param scorer: Scorer file</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">@Retval</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Returns a DeepSpeech Object</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> load_model</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">models</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> scorer</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    to load up the model and scorer for DeepSpeech to run speech to text with. This function takes two parameters, the models graph, which we create a function to produce below, and the path to the scorer file. All it does is load the model from the graph and enable the use of the scorer. This function returns a DeepSpeech object.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    ds </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> Model</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(models)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    ds.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">enableExternalScorer</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(scorer)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ds</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Speech to Text on an Audio File with DeepSpeech</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Run Inference on input audio file</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">@param ds: Deepspeech object</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">@param audio: Input audio for running inference on</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">@param fs: Sample rate of the input audio file</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">@Retval:</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Returns a list [Inference, Inference Time, Audio Length]</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> stt</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">ds</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> audio</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> fs</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    This function is the one that does the actual speech recognition. It takes three inputs, a DeepSpeech model, the audio data, and the sample rate.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    </span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    We begin by setting the time to 0 and calculating the length of the audio. All we really have to do is call the DeepSpeech model’s stt function to do our own stt function. We pass the audio file to the stt function and return the output.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    inference_time </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 0.0</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    audio_length </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(audio) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">*</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> /</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> fs)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # Run Deepspeech</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    output </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ds.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">stt</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(audio)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> output</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># DeepSpeech Model Graph Creator Function</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Resolve directory path for the models and fetch each of them.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">@param dirName: Path to the directory containing pre-trained models</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">@Retval:</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Retunns a tuple containing each of the model files (pb, scorer)</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> resolve_models</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">dirName</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    This is the function that creates the model graph for the load_model function we created a couple sections above. This function takes the path to a directory. From that directory, it looks for files with the DeepSpeech model extension, pbmm and the DeepSpeech scorer file extension, .scorer. Then, it returns both of those values.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    pb </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> glob.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">glob</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(dirName </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;/*.pbmm&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    logging.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">debug</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Found Model: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">%s</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> %</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pb)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    scorer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> glob.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">glob</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(dirName </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;/*.scorer&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    logging.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">debug</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Found scorer: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">%s</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> %</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> scorer)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pb, scorer</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Voice Activation Detection to Create Segments for Speech to Text</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Generate VAD segments. Filters out non-voiced audio frames.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">@param waveFile: Input wav file to run VAD on.0</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">@Retval:</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Returns tuple of</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">   segments: a bytearray of multiple smaller audio frames</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">             (The longer audio split into mutiple smaller one&#39;s)</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">   sample_rate: Sample rate of the input audio file</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">   audio_length: Duraton of the input audio file</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> vad_segment_generator</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">wavFile</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> aggressiveness</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    The last function in our WAV transcription file generates segments of text that contain voice. We use the WAV handler file we created earlier and webrtcvad to do the heavy lifting. This function requires two parameters: a WAV file and an integer value from 0 to 3 representing how aggressively we want to filter out non-voice activity.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    </span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    We call the read_wave function from the wav_handler.py file we created earlier and imported above to get the audio data, sample rate, and audio length. We then assert that the sample rate is 16kHz before moving on to create a VAD object. Next, we call the frame generator from wav_handler.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    </span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    We convert the generated iterator to a list which we pass to the vad_collector function from wav_handler along with the sample rate, frame duration (30 ms), padding duration (300 ms), and VAD object. Finally, we return the collected VAD segments along with the sample rate and audio length.</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    audio, sample_rate, audio_length </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wav_handler.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">read_wave</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(wavFile)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    assert</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> sample_rate </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">==</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 16000</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Only 16000Hz input WAV files are supported for now!&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    vad </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> webrtcvad.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Vad</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">int</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(aggressiveness))</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    frames </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wav_handler.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">frame_generator</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">30</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, audio, sample_rate)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    frames </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> list</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(frames)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    segments </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wav_handler.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">vad_collector</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(sample_rate, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">30</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">300</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, vad, frames)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> segments, sample_rate, audio_length</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="reading-arguments-for-deepspeech-speech-to-text" tabindex="-1"><a class="header-anchor" href="#reading-arguments-for-deepspeech-speech-to-text"><span>Reading Arguments for DeepSpeech Speech to Text</span></a></h3><p>We create a main function that takes one parameter — <code>args</code>. These are the arguments passed in through the command line. We use the <code>argparse</code> library to parse the arguments sent in. We also create helpful tips on how to use each one.</p><p>We use <code>aggressive</code> to determine how aggressively we want to filter. audio directs us to the audio file path. model points us to the directory containing the model and scorer. Finally, stream dictates whether or not we are streaming audio. Neither stream nor audio is required, but one or the other must be present.</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> sys</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> logging</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> argparse</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> subprocess</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> shlex</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> numpy </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> np</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wav_transcriber</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Debug helpers</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">logging.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">basicConfig</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">stream</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">sys.stderr, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">level</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">logging.</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">DEBUG</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> main</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">args</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    parser </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> argparse.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">ArgumentParser</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">description</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;Transcribe long audio files using webRTC VAD or use the streaming interface&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">add_argument</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;--aggressive&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">type</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">int</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">choices</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">range</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">required</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                       help</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;Determines how aggressive filtering out non-speech is. (Interger between 0-3)&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">add_argument</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;--audio&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">required</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                       help</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;Path to the audio file to run (WAV format)&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">add_argument</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;--model&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">required</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                       help</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;Path to directory that contains all model files (output_graph and scorer)&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">add_argument</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;--stream&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">required</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">action</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;store_true&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                       help</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;To use deepspeech streaming interface&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    args </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">parse_args</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.stream </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">is</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Opening mic for streaming&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    elif</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.audio </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">is</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> not</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        logging.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">debug</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Transcribing audio file @ </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">%s</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> %</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.audio)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    else</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">print_help</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">exit</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="using-deepspeech-for-real-time-or-asynchronous-speech-recognition" tabindex="-1"><a class="header-anchor" href="#using-deepspeech-for-real-time-or-asynchronous-speech-recognition"><span>Using DeepSpeech for Real Time or Asynchronous Speech Recognition</span></a></h3><p>This is still inside the main function we started above. Once we parse all the arguments, we load up DeepSpeech. First, we get the directory containing the models. Next, we call the <code>wav_transcriber</code> to resolve and load the models.</p><p>If we pass the path to an audio data file in the command line, then we will run asynchronous speech recognition. The first thing we do for that is call the VAD segment generator to generate the VAD segments and get the sample rate and audio length. Next, we open up a text file to transcribe to.</p><p>For each of the enumerated segments, we will process each chunk by using <code>numpy</code> to pull the segment from the buffer and the speech to text function from <code>wav_transcriber</code> to do the speech to text functionality. We write to the text file until we run out of audio segments.</p><p>If we pass stream instead of audio, then we open up the mic to stream audio data in. If you don’t need real time automatic speech recognition, then you can ignore this part. First, we have to spin up a subprocess to open up a mic to stream in real time just like we did with PyTorch local speech recognition.</p><p>We use the <code>subprocess</code> and <code>shlex</code> libraries to open the mic to stream voice audio until we shut it down. The model will read 512 bytes of audio data at a time and transcribe it.</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Point to a path containing the pre-trained models &amp; resolve ~ if used</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">dirName </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">expanduser</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(args.model)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Resolve all the paths of model files</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">output_graph, scorer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wav_transcriber.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">resolve_models</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(dirName)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Load output_graph, alpahbet and scorer</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">model_retval </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wav_transcriber.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">load_model</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(output_graph, scorer)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.audio </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">is</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> not</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # Run VAD on the input file</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    waveFile </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.audio</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    segments, sample_rate, audio_length </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wav_transcriber.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">vad_segment_generator</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(waveFile, args.aggressive)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    f </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> open</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(waveFile.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">rstrip</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;.wav&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;.txt&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;w&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    logging.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">debug</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Saving Transcript @: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">%s</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> %</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> waveFile.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">rstrip</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;.wav&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;.txt&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> i, segment </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> enumerate</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(segments):</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # Run deepspeech on the chunk that just completed VAD</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        logging.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">debug</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Processing chunk </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">%002d</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> %</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (i,))</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        audio </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> np.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">frombuffer</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(segment, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">np.int16)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        output </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> wav_transcriber.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">stt</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(model_retval, audio, sample_rate)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        logging.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">debug</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Transcript: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">%s</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> %</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> output)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        f.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">write</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(output </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot; &quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # Summary of the files processed</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    f.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">close</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">else</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    sctx </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> model_retval.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">createStream</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    subproc </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> subprocess.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Popen</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(shlex.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">split</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;rec -q -V0 -e signed -L -c 1 -b 16 -r 16k -t raw - gain -2&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">),</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                                stdout</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">subprocess.</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">PIPE</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                                bufsize</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">    print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;You can start speaking now. Press Control-C to stop recording.&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    try</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        while</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            data </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> subproc.stdout.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">read</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">512</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            sctx.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">feedAudioContent</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(np.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">frombuffer</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(data, np.int16))</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    except</span><span style="--shiki-light:#0184BC;--shiki-dark:#ABB2BF;"> KeyboardInterrupt</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;Transcription: &#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, sctx.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">finishStream</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">())</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        subproc.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">terminate</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        subproc.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">wait</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> __name__</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> ==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;__main__&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">    main</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(sys.argv[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:])</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="resource" tabindex="-1"><a class="header-anchor" href="#resource"><span>Resource</span></a></h2><p><a href="https://medium.com/plain-simple-software/a-guide-to-deepspeech-speech-to-text-b4b051477cfa" target="_blank" rel="noopener noreferrer">A Guide to DeepSpeech Speech to Text</a></p></div><!----><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/techniques/AI/Others/Gemini.html" aria-label="API usuage"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span>API usuage</div></a><a class="route-link auto-link next" href="/techniques/AI/Others/04.Speech2Text.html" aria-label="Audio to Text (OpenAI)"><div class="hint">Next<span class="arrow end"></span></div><div class="link">Audio to Text (OpenAI)<span class="font-icon icon fa-fw fa-sm fas fa-circle-dot" style=""></span></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">Email me if needed</div><div class="vp-copyright">Copyright © 2024 Haiyue </div></footer></div><!--]--><!--[--><!----><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-CQersmFQ.js" defer></script>
  </body>
</html>
