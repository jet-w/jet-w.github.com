import{_ as n}from"./plugin-vue_export-helper-c27b6911.js";import{r as a,o as s,c as l,a as i,b as e,d as t,e as r}from"./app-42f99355.js";const h={},c=e("h2",{id:"building-detection-geoscience",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#building-detection-geoscience","aria-hidden":"true"},"#"),t(" Building Detection (Geoscience)")],-1),g={href:"https://huggingface.co/datasets/keremberke/satellite-building-segmentation/viewer/mini/test",target:"_blank",rel:"noopener noreferrer"},d={href:"https://huggingface.co/ratnaonline1/segFormer-b4-city-satellite-segmentation-1024x1024",target:"_blank",rel:"noopener noreferrer"},_={href:"https://www.kaggle.com/code/kmader/segmenting-buildings-in-satellite-images",target:"_blank",rel:"noopener noreferrer"},f={href:"https://huggingface.co/facebook/mask2former-swin-large-mapillary-vistas-panoptic/tree/main",target:"_blank",rel:"noopener noreferrer"},u={href:"https://huggingface.co/thiagohersan/maskformer-satellite-trees",target:"_blank",rel:"noopener noreferrer"},p=e("h2",{id:"voice-cloning",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#voice-cloning","aria-hidden":"true"},"#"),t(" Voice Cloning")],-1),m={href:"https://huggingface.co/dog/kanye",target:"_blank",rel:"noopener noreferrer"},b={href:"https://huggingface.co/spaces/akhaliq/Real-Time-Voice-Cloning",target:"_blank",rel:"noopener noreferrer"},k={href:"https://huggingface.co/anton-l/wav2vec2-xls-r-common_voice-tr-ft-stream",target:"_blank",rel:"noopener noreferrer"},x=e("h2",{id:"image-super-resolution",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#image-super-resolution","aria-hidden":"true"},"#"),t(" Image Super Resolution")],-1),v=e("li",null,"Search super-resolution in huggingface",-1),y={href:"https://magnific.substack.com/",target:"_blank",rel:"noopener noreferrer"},w={href:"https://github.com/IBM/MAX-Image-Resolution-Enhancer",target:"_blank",rel:"noopener noreferrer"},S={href:"https://huggingface.co/keras-io/super-resolution/blob/main/README.md",target:"_blank",rel:"noopener noreferrer"},T={href:"https://huggingface.co/CompVis/ldm-super-resolution-4x-openimages",target:"_blank",rel:"noopener noreferrer"},V=e("h2",{id:"image-clear",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#image-clear","aria-hidden":"true"},"#"),t(" Image clear")],-1),C={href:"https://huggingface.co/google/maxim-s3-deblurring-gopro",target:"_blank",rel:"noopener noreferrer"},D={href:"https://github.com/sayakpaul/maxim-tf",target:"_blank",rel:"noopener noreferrer"},I={href:"https://github.com/google-research/maxim",target:"_blank",rel:"noopener noreferrer"},A={href:"https://github.com/megvii-research/NAFNet?tab=readme-ov-file",target:"_blank",rel:"noopener noreferrer"},M=e("h2",{id:"speech2text",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#speech2text","aria-hidden":"true"},"#"),t(" Speech2Text:")],-1),R={href:"https://huggingface.co/docs/transformers/model_doc/speech_to_text",target:"_blank",rel:"noopener noreferrer"},E={href:"https://huggingface.co/docs/transformers/model_doc/speech_to_text_2",target:"_blank",rel:"noopener noreferrer"},B={href:"https://turboscribe.ai/dashboard",target:"_blank",rel:"noopener noreferrer"},H={href:"https://huggingface.co/wbbbbb/wav2vec2-large-chinese-zh-cn",target:"_blank",rel:"noopener noreferrer"},N=e("strong",null,"Important",-1),q={href:"https://cloud.google.com/speech-to-text/docs/speech-to-text-supported-languages",target:"_blank",rel:"noopener noreferrer"},G={href:"https://huggingface.co/openai/whisper-large-v3",target:"_blank",rel:"noopener noreferrer"},L=e("h2",{id:"digital-human",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#digital-human","aria-hidden":"true"},"#"),t(" Digital Human")],-1),X={href:"https://huggingface.co/CiroN2022/digital-human",target:"_blank",rel:"noopener noreferrer"},z={href:"https://huggingface.co/Kedreamix/Digital-Human-Weights",target:"_blank",rel:"noopener noreferrer"},j={href:"https://huggingface.co/papers/2307.05462",target:"_blank",rel:"noopener noreferrer"},K={href:"https://huggingface.co/papers/2305.11870",target:"_blank",rel:"noopener noreferrer"},W={href:"https://medium.com/@black_51980/creating-digital-humans-capture-modeling-and-synthesis-1612dbcbcaa4",target:"_blank",rel:"noopener noreferrer"},F={href:"https://sourceforge.net/software/digital-human/",target:"_blank",rel:"noopener noreferrer"},O={href:"https://medium.com/antaeus-ar/the-world-of-digital-humans-where-ai-meets-realism-5e4955b8261c",target:"_blank",rel:"noopener noreferrer"},P={href:"https://github.com/weihaox/awesome-digital-human",target:"_blank",rel:"noopener noreferrer"},Y={href:"https://sourceforge.net/software/digital-human/integrates-with-blender/",target:"_blank",rel:"noopener noreferrer"},J=e("h2",{id:"image-to-video",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#image-to-video","aria-hidden":"true"},"#"),t(" Image to Video")],-1),U={href:"https://huggingface.co/motexture/VSeq2VSeq",target:"_blank",rel:"noopener noreferrer"},Q=e("br",null,null,-1),Z={href:"https://github.com/alibaba/animate-anything",target:"_blank",rel:"noopener noreferrer"},$=e("br",null,null,-1),ee={href:"https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt",target:"_blank",rel:"noopener noreferrer"},te=e("h2",{id:"text-to-video",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#text-to-video","aria-hidden":"true"},"#"),t(" Text to Video")],-1),oe={href:"https://huggingface.co/hotshotco/Hotshot-XL",target:"_blank",rel:"noopener noreferrer"},re=e("br",null,null,-1),ne={href:"https://huggingface.co/cerspense/zeroscope_v2_576w",target:"_blank",rel:"noopener noreferrer"},ae=e("span",{style:{color:"orange","font-weight":"bold"}},"cerspense/zeroscope_v2_576w",-1),se=e("br",null,null,-1),le={href:"https://huggingface.co/damo-vilab/text-to-video-ms-1.7b",target:"_blank",rel:"noopener noreferrer"},ie=e("span",{style:{color:"orange","font-weight":"bold"}},"damo-vilab/text-to-video-ms-1.7b",-1),he=e("br",null,null,-1),ce={href:"https://huggingface.co/damo-vilab/modelscope-damo-text-to-video-synthesis",target:"_blank",rel:"noopener noreferrer"},ge=e("br",null,null,-1),de={href:"https://huggingface.co/guoyww/animatediff-motion-adapter-v1-5-2",target:"_blank",rel:"noopener noreferrer"},_e=e("br",null,null,-1),fe={href:"https://huggingface.co/camenduru/potat1",target:"_blank",rel:"noopener noreferrer"},ue=e("br",null,null,-1),pe={href:"https://huggingface.co/guoyww/animatediff-motion-lora-zoom-in",target:"_blank",rel:"noopener noreferrer"},me=e("h2",{id:"text-to-speech",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#text-to-speech","aria-hidden":"true"},"#"),t(" Text to Speech")],-1),be={href:"https://huggingface.co/coqui/XTTS-v2",target:"_blank",rel:"noopener noreferrer"},ke=e("span",{style:{color:"red","font-weight":"bold"}},"Support Chinese, voice clone, emotion, etc..",-1),xe={href:"https://huggingface.co/speechbrain/tts-tacotron2-ljspeech",target:"_blank",rel:"noopener noreferrer"},ve={href:"https://huggingface.co/facebook/fastspeech2-en-ljspeech",target:"_blank",rel:"noopener noreferrer"},ye=e("span",{style:{color:"orange"}},"Only English is supported",-1),we={href:"https://huggingface.co/suno/bark-small",target:"_blank",rel:"noopener noreferrer"},Se=e("span",{style:{}},"More research is needed, not good enough as example on colab",-1),Te={href:"https://huggingface.co/microsoft/speecht5_tts",target:"_blank",rel:"noopener noreferrer"},Ve=e("span",{style:{color:"orange"}},"Effect is good, need to find models for other languages",-1),Ce=e("br",null,null,-1),De={href:"https://github.com/microsoft/SpeechT5/",target:"_blank",rel:"noopener noreferrer"},Ie={href:"https://huggingface.co/facebook/mms-tts-eng",target:"_blank",rel:"noopener noreferrer"},Ae=e("span",{style:{color:"orange"}},"Example efficient is good, need to explore for other language.",-1),Me={href:"https://huggingface.co/suno/bark",target:"_blank",rel:"noopener noreferrer"},Re={href:"https://colab.research.google.com/drive/1eJfA2XUa-mXwdMy7DoYKVYHI1iTd9Vkt?usp=sharing#scrollTo=t9Vlr3RRt6B9",target:"_blank",rel:"noopener noreferrer"},Ee=e("h2",{id:"text-to-image",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#text-to-image","aria-hidden":"true"},"#"),t(" Text to Image")],-1),Be={href:"https://huggingface.co/dataautogpt3/OpenDalleV1.1",target:"_blank",rel:"noopener noreferrer"},He=e("span",{style:{color:"orange","font-weight":"bold"}},"dataautogpt3/OpenDalleV1.1",-1),Ne=e("strong",null,"Good",-1),qe={href:"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0",target:"_blank",rel:"noopener noreferrer"},Ge=e("span",{style:{color:"orange","font-weight":"bold"}},"stabilityai/stable-diffusion-xl-base-1.0",-1),Le=e("strong",null,"Better",-1),Xe=e("h2",{id:"sketch",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#sketch","aria-hidden":"true"},"#"),t(" Sketch")],-1),ze={href:"https://huggingface.co/TencentARC/t2i-adapter-sketch-sdxl-1.0",target:"_blank",rel:"noopener noreferrer"},je=e("br",null,null,-1),Ke={href:"https://huggingface.co/TencentARC/t2iadapter_sketch_sd15v2",target:"_blank",rel:"noopener noreferrer"},We={href:"https://huggingface.co/cosc/sketchstyle-cutesexyrobutts",target:"_blank",rel:"noopener noreferrer"},Fe={href:"https://huggingface.co/microsoft/beit-base-patch16-224-pt22k-ft22k",target:"_blank",rel:"noopener noreferrer"},Oe=e("br",null,null,-1),Pe={href:"https://huggingface.co/Linaqruf/sketch-style-xl-lora",target:"_blank",rel:"noopener noreferrer"};function Ye(Je,Ue){const o=a("ExternalLinkIcon");return s(),l("div",null,[i(`
## Generate Video
1. stable video diffusion: generate video
1. [Stability-AI](https://github.com/Stability-AI/generative-models?tab=readme-ov-file)`),c,e("ol",null,[e("li",null,[e("a",g,[t("Datasets for satellite building segmentation"),r(o)])]),e("li",null,[e("a",d,[t("Model for satellite city segmentation"),r(o)])]),e("li",null,[e("a",_,[t("Segmenting Buildings in Satellite Images"),r(o)])]),e("li",null,[e("a",f,[t("Mask2former swin large mapillary vistas panoptic"),r(o)])]),e("li",null,[e("a",u,[t("Maskformer Satellite Trees"),r(o)])])]),p,e("ol",null,[e("li",null,[e("a",m,[t("Model for Kanye voice cloning"),r(o)])]),e("li",null,[e("a",b,[t("Real Time Voice Cloning"),r(o)])]),e("li",null,[e("a",k,[t("https://huggingface.co/anton-l/wav2vec2-xls-r-common_voice-tr-ft-stream"),r(o)])])]),x,e("ol",null,[v,e("li",null,[e("a",y,[t("magnific"),r(o)])]),e("li",null,[e("a",w,[t("Image Resolution Enhancer (IBM)"),r(o)])]),e("li",null,[e("a",S,[t("keras-io/super-resolution"),r(o)])]),e("li",null,[e("a",T,[t("ldm-super-resolution-4x-openimages"),r(o)])])]),V,e("ol",null,[e("li",null,[e("a",C,[t("deblur"),r(o)])]),e("li",null,[e("a",D,[t("maxim-tf"),r(o)])]),e("li",null,[e("a",I,[t("maxim"),r(o)])]),e("li",null,[e("a",A,[t("NAFNet"),r(o)])])]),M,e("ol",null,[e("li",null,[e("a",R,[t("Speech to Text"),r(o)])]),e("li",null,[e("a",E,[t("Speech to Text 2"),r(o)])]),e("li",null,[e("a",B,[t("turboscribe.ai"),r(o)])]),e("li",null,[e("a",H,[t("wbbbbb/wav2vec2-large-chinese-zh-cn"),r(o)]),t(),N]),e("li",null,[e("a",q,[t("Google speech to text supported languages"),r(o)])]),e("li",null,[e("a",G,[t("openai/whisper-large-v3"),r(o)])])]),L,e("ol",null,[e("li",null,[e("a",X,[t("CiroN2022/digital-human"),r(o)])]),e("li",null,[e("a",z,[t("Kedreamix/Digital-Human-Weights"),r(o)])]),e("li",null,[e("a",j,[t("Efficient 3D Articulated Human Generation with Layered Surface Volumes"),r(o)])]),e("li",null,[e("a",K,[t("Chupa: Carving 3D Clothed Humans from Skinned Shape Priors using 2D Diffusion Probabilistic Models"),r(o)])]),e("li",null,[e("a",W,[t("Creating digital humans: Capture, Modeling, and Synthesis"),r(o)])]),e("li",null,[e("a",F,[t("Digital-human on Sourceforge"),r(o)])]),e("li",null,[e("a",O,[t("The World of Digital Humans: Where AI Meets Realism"),r(o)])]),e("li",null,[e("a",P,[t("awesome-digital-human"),r(o)])]),e("li",null,[e("a",Y,[t("Digital Human Software for Blender"),r(o)])])]),J,e("p",null,[e("a",U,[t("motexture/VSeq2VSeq"),r(o)]),Q,e("a",Z,[t("animate anything"),r(o)]),$,e("a",ee,[t("stabilityai/stable-video-diffusion-img2vid-xt"),r(o)])]),te,e("p",null,[e("a",oe,[t("hotshotco/Hotshot-XL"),r(o)]),re,e("a",ne,[ae,r(o)]),se,e("a",le,[ie,r(o)]),he,e("a",ce,[t("damo-vilab/modelscope-damo-text-to-video-synthesis"),r(o)]),ge,e("a",de,[t("guoyww/animatediff-motion-adapter-v1-5-2"),r(o)]),_e,e("a",fe,[t("camenduru/potat1"),r(o)]),ue,e("a",pe,[t("guoyww/animatediff-motion-lora-zoom-in"),r(o)])]),me,e("ol",null,[e("li",null,[e("a",be,[t("coqui/XTTS-v2"),r(o)]),t(),ke]),e("li",null,[e("a",xe,[t("speechbrain/tts-tacotron2-ljspeech"),r(o)])]),e("li",null,[e("a",ve,[t("facebook/fastspeech2-en-ljspeech"),r(o)]),t(),ye]),e("li",null,[e("a",we,[t("suno/bark-small"),r(o)]),t(),Se]),e("li",null,[e("a",Te,[t("microsoft/speecht5_tts"),r(o)]),t(),Ve,Ce,e("a",De,[t("SpeechT5 on Github"),r(o)])]),e("li",null,[e("a",Ie,[t("facebook/mms-tts-eng"),r(o)]),Ae]),e("li",null,[e("a",Me,[t("suno/bark"),r(o)]),t(),e("a",Re,[t("Example on Google Colab"),r(o)])])]),Ee,e("ol",null,[e("li",null,[e("a",Be,[He,r(o)]),t(),Ne]),e("li",null,[e("a",qe,[Ge,r(o)]),t(),Le])]),Xe,e("p",null,[e("a",ze,[t("TencentARC/t2i-adapter-sketch-sdxl-1.0"),r(o)]),t(" **"),je,e("a",Ke,[t("TencentARC/t2iadapter_sketch_sd15v2"),r(o)]),t(" **")]),e("p",null,[e("a",We,[t("cosc/sketchstyle-cutesexyrobutts"),r(o)])]),e("p",null,[e("a",Fe,[t("microsoft/beit-base-patch16-224-pt22k-ft22k"),r(o)]),Oe,e("a",Pe,[t("Linaqruf/sketch-style-xl-lora"),r(o)])])])}const $e=n(h,[["render",Ye],["__file","01.ai_models.html.vue"]]);export{$e as default};
