import{_ as n}from"./plugin-vue_export-helper-c27b6911.js";import{r as a,o as s,c as l,b as e,d as t,e as r}from"./app-12682a34.js";const i={},h=e("h2",{id:"generate-video",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#generate-video","aria-hidden":"true"},"#"),t(" Generate Video")],-1),c=e("li",null,"stable video diffusion: generate video",-1),g={href:"https://github.com/Stability-AI/generative-models?tab=readme-ov-file",target:"_blank",rel:"noopener noreferrer"},d=e("h2",{id:"building-detection-geoscience",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#building-detection-geoscience","aria-hidden":"true"},"#"),t(" Building Detection (Geoscience)")],-1),_={href:"https://huggingface.co/datasets/keremberke/satellite-building-segmentation/viewer/mini/test",target:"_blank",rel:"noopener noreferrer"},u={href:"https://huggingface.co/ratnaonline1/segFormer-b4-city-satellite-segmentation-1024x1024",target:"_blank",rel:"noopener noreferrer"},f={href:"https://www.kaggle.com/code/kmader/segmenting-buildings-in-satellite-images",target:"_blank",rel:"noopener noreferrer"},p={href:"https://huggingface.co/facebook/mask2former-swin-large-mapillary-vistas-panoptic/tree/main",target:"_blank",rel:"noopener noreferrer"},m={href:"https://huggingface.co/thiagohersan/maskformer-satellite-trees",target:"_blank",rel:"noopener noreferrer"},b=e("h2",{id:"voice-cloning",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#voice-cloning","aria-hidden":"true"},"#"),t(" Voice Cloning")],-1),k={href:"https://huggingface.co/dog/kanye",target:"_blank",rel:"noopener noreferrer"},x={href:"https://huggingface.co/spaces/akhaliq/Real-Time-Voice-Cloning",target:"_blank",rel:"noopener noreferrer"},v={href:"https://huggingface.co/anton-l/wav2vec2-xls-r-common_voice-tr-ft-stream",target:"_blank",rel:"noopener noreferrer"},y=e("h2",{id:"image-super-resolution",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#image-super-resolution","aria-hidden":"true"},"#"),t(" Image Super Resolution")],-1),w=e("li",null,"Search super-resolution in huggingface",-1),S={href:"https://magnific.substack.com/",target:"_blank",rel:"noopener noreferrer"},T={href:"https://github.com/IBM/MAX-Image-Resolution-Enhancer",target:"_blank",rel:"noopener noreferrer"},V={href:"https://huggingface.co/keras-io/super-resolution/blob/main/README.md",target:"_blank",rel:"noopener noreferrer"},C={href:"https://huggingface.co/CompVis/ldm-super-resolution-4x-openimages",target:"_blank",rel:"noopener noreferrer"},D=e("h2",{id:"image-clear",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#image-clear","aria-hidden":"true"},"#"),t(" Image clear")],-1),I={href:"https://huggingface.co/google/maxim-s3-deblurring-gopro",target:"_blank",rel:"noopener noreferrer"},A={href:"https://github.com/sayakpaul/maxim-tf",target:"_blank",rel:"noopener noreferrer"},M={href:"https://github.com/google-research/maxim",target:"_blank",rel:"noopener noreferrer"},R={href:"https://github.com/megvii-research/NAFNet?tab=readme-ov-file",target:"_blank",rel:"noopener noreferrer"},E=e("h2",{id:"speech2text",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#speech2text","aria-hidden":"true"},"#"),t(" Speech2Text:")],-1),q={href:"https://huggingface.co/docs/transformers/model_doc/speech_to_text",target:"_blank",rel:"noopener noreferrer"},H={href:"https://huggingface.co/docs/transformers/model_doc/speech_to_text_2",target:"_blank",rel:"noopener noreferrer"},B={href:"https://turboscribe.ai/dashboard",target:"_blank",rel:"noopener noreferrer"},N={href:"https://huggingface.co/wbbbbb/wav2vec2-large-chinese-zh-cn",target:"_blank",rel:"noopener noreferrer"},L=e("strong",null,"Important",-1),X={href:"https://cloud.google.com/speech-to-text/docs/speech-to-text-supported-languages",target:"_blank",rel:"noopener noreferrer"},z=e("h2",{id:"digital-human",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#digital-human","aria-hidden":"true"},"#"),t(" Digital Human")],-1),G={href:"https://huggingface.co/CiroN2022/digital-human",target:"_blank",rel:"noopener noreferrer"},j={href:"https://huggingface.co/Kedreamix/Digital-Human-Weights",target:"_blank",rel:"noopener noreferrer"},F={href:"https://huggingface.co/papers/2307.05462",target:"_blank",rel:"noopener noreferrer"},K={href:"https://huggingface.co/papers/2305.11870",target:"_blank",rel:"noopener noreferrer"},W={href:"https://medium.com/@black_51980/creating-digital-humans-capture-modeling-and-synthesis-1612dbcbcaa4",target:"_blank",rel:"noopener noreferrer"},O={href:"https://sourceforge.net/software/digital-human/",target:"_blank",rel:"noopener noreferrer"},P={href:"https://medium.com/antaeus-ar/the-world-of-digital-humans-where-ai-meets-realism-5e4955b8261c",target:"_blank",rel:"noopener noreferrer"},Y={href:"https://github.com/weihaox/awesome-digital-human",target:"_blank",rel:"noopener noreferrer"},J={href:"https://sourceforge.net/software/digital-human/integrates-with-blender/",target:"_blank",rel:"noopener noreferrer"},U=e("h2",{id:"image-to-video",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#image-to-video","aria-hidden":"true"},"#"),t(" Image to Video")],-1),Q={href:"https://huggingface.co/motexture/VSeq2VSeq",target:"_blank",rel:"noopener noreferrer"},Z=e("br",null,null,-1),$={href:"https://github.com/alibaba/animate-anything",target:"_blank",rel:"noopener noreferrer"},ee=e("br",null,null,-1),te={href:"https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt",target:"_blank",rel:"noopener noreferrer"},oe=e("h2",{id:"text-to-video",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#text-to-video","aria-hidden":"true"},"#"),t(" Text to Video")],-1),re={href:"https://huggingface.co/hotshotco/Hotshot-XL",target:"_blank",rel:"noopener noreferrer"},ne=e("br",null,null,-1),ae={href:"https://huggingface.co/cerspense/zeroscope_v2_576w",target:"_blank",rel:"noopener noreferrer"},se=e("span",{style:{color:"orange","font-weight":"bold"}},"cerspense/zeroscope_v2_576w",-1),le=e("br",null,null,-1),ie={href:"https://huggingface.co/damo-vilab/text-to-video-ms-1.7b",target:"_blank",rel:"noopener noreferrer"},he=e("span",{style:{color:"orange","font-weight":"bold"}},"damo-vilab/text-to-video-ms-1.7b",-1),ce=e("br",null,null,-1),ge={href:"https://huggingface.co/damo-vilab/modelscope-damo-text-to-video-synthesis",target:"_blank",rel:"noopener noreferrer"},de=e("br",null,null,-1),_e={href:"https://huggingface.co/guoyww/animatediff-motion-adapter-v1-5-2",target:"_blank",rel:"noopener noreferrer"},ue=e("br",null,null,-1),fe={href:"https://huggingface.co/camenduru/potat1",target:"_blank",rel:"noopener noreferrer"},pe=e("br",null,null,-1),me={href:"https://huggingface.co/guoyww/animatediff-motion-lora-zoom-in",target:"_blank",rel:"noopener noreferrer"},be=e("h2",{id:"text-to-speech",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#text-to-speech","aria-hidden":"true"},"#"),t(" Text to Speech")],-1),ke={href:"https://huggingface.co/coqui/XTTS-v2",target:"_blank",rel:"noopener noreferrer"},xe=e("span",{style:{color:"red"}},"Failed to install the required packages",-1),ve={href:"https://huggingface.co/speechbrain/tts-tacotron2-ljspeech",target:"_blank",rel:"noopener noreferrer"},ye={href:"https://huggingface.co/facebook/fastspeech2-en-ljspeech",target:"_blank",rel:"noopener noreferrer"},we=e("span",{style:{color:"orange"}},"Only English is supported",-1),Se={href:"https://huggingface.co/suno/bark-small",target:"_blank",rel:"noopener noreferrer"},Te=e("span",{style:{}},"More research is needed, not good enough as example on colab",-1),Ve={href:"https://huggingface.co/microsoft/speecht5_tts",target:"_blank",rel:"noopener noreferrer"},Ce=e("span",{style:{color:"orange"}},"Effect is good, need to find models for other languages",-1),De=e("br",null,null,-1),Ie={href:"https://github.com/microsoft/SpeechT5/",target:"_blank",rel:"noopener noreferrer"},Ae={href:"https://huggingface.co/facebook/mms-tts-eng",target:"_blank",rel:"noopener noreferrer"},Me=e("span",{style:{color:"orange"}},"Example efficient is good, need to explore for other language.",-1),Re={href:"https://huggingface.co/suno/bark",target:"_blank",rel:"noopener noreferrer"},Ee=e("span",{style:{color:"orange"}},"Cannot install successfully with python3.11",-1),qe={href:"https://colab.research.google.com/drive/1eJfA2XUa-mXwdMy7DoYKVYHI1iTd9Vkt?usp=sharing#scrollTo=t9Vlr3RRt6B9",target:"_blank",rel:"noopener noreferrer"},He=e("h2",{id:"text-to-image",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#text-to-image","aria-hidden":"true"},"#"),t(" Text to Image")],-1),Be={href:"https://huggingface.co/dataautogpt3/OpenDalleV1.1",target:"_blank",rel:"noopener noreferrer"},Ne=e("span",{style:{color:"orange","font-weight":"bold"}},"dataautogpt3/OpenDalleV1.1",-1),Le=e("h2",{id:"sketch",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#sketch","aria-hidden":"true"},"#"),t(" Sketch")],-1),Xe={href:"https://huggingface.co/TencentARC/t2i-adapter-sketch-sdxl-1.0",target:"_blank",rel:"noopener noreferrer"},ze=e("br",null,null,-1),Ge={href:"https://huggingface.co/TencentARC/t2iadapter_sketch_sd15v2",target:"_blank",rel:"noopener noreferrer"},je={href:"https://huggingface.co/cosc/sketchstyle-cutesexyrobutts",target:"_blank",rel:"noopener noreferrer"},Fe={href:"https://huggingface.co/microsoft/beit-base-patch16-224-pt22k-ft22k",target:"_blank",rel:"noopener noreferrer"},Ke=e("br",null,null,-1),We={href:"https://huggingface.co/Linaqruf/sketch-style-xl-lora",target:"_blank",rel:"noopener noreferrer"};function Oe(Pe,Ye){const o=a("ExternalLinkIcon");return s(),l("div",null,[h,e("ol",null,[c,e("li",null,[e("a",g,[t("Stability-AI"),r(o)])])]),d,e("ol",null,[e("li",null,[e("a",_,[t("Datasets for satellite building segmentation"),r(o)])]),e("li",null,[e("a",u,[t("Model for satellite city segmentation"),r(o)])]),e("li",null,[e("a",f,[t("Segmenting Buildings in Satellite Images"),r(o)])]),e("li",null,[e("a",p,[t("Mask2former swin large mapillary vistas panoptic"),r(o)])]),e("li",null,[e("a",m,[t("Maskformer Satellite Trees"),r(o)])])]),b,e("ol",null,[e("li",null,[e("a",k,[t("Model for Kanye voice cloning"),r(o)])]),e("li",null,[e("a",x,[t("Real Time Voice Cloning"),r(o)])]),e("li",null,[e("a",v,[t("https://huggingface.co/anton-l/wav2vec2-xls-r-common_voice-tr-ft-stream"),r(o)])])]),y,e("ol",null,[w,e("li",null,[e("a",S,[t("magnific"),r(o)])]),e("li",null,[e("a",T,[t("Image Resolution Enhancer (IBM)"),r(o)])]),e("li",null,[e("a",V,[t("keras-io/super-resolution"),r(o)])]),e("li",null,[e("a",C,[t("ldm-super-resolution-4x-openimages"),r(o)])])]),D,e("ol",null,[e("li",null,[e("a",I,[t("deblur"),r(o)])]),e("li",null,[e("a",A,[t("maxim-tf"),r(o)])]),e("li",null,[e("a",M,[t("maxim"),r(o)])]),e("li",null,[e("a",R,[t("NAFNet"),r(o)])])]),E,e("ol",null,[e("li",null,[e("a",q,[t("Speech to Text"),r(o)])]),e("li",null,[e("a",H,[t("Speech to Text 2"),r(o)])]),e("li",null,[e("a",B,[t("turboscribe.ai"),r(o)])]),e("li",null,[e("a",N,[t("wbbbbb/wav2vec2-large-chinese-zh-cn"),r(o)]),t(),L]),e("li",null,[e("a",X,[t("Google speech to text supported languages"),r(o)])])]),z,e("ol",null,[e("li",null,[e("a",G,[t("CiroN2022/digital-human"),r(o)])]),e("li",null,[e("a",j,[t("Kedreamix/Digital-Human-Weights"),r(o)])]),e("li",null,[e("a",F,[t("Efficient 3D Articulated Human Generation with Layered Surface Volumes"),r(o)])]),e("li",null,[e("a",K,[t("Chupa: Carving 3D Clothed Humans from Skinned Shape Priors using 2D Diffusion Probabilistic Models"),r(o)])]),e("li",null,[e("a",W,[t("Creating digital humans: Capture, Modeling, and Synthesis"),r(o)])]),e("li",null,[e("a",O,[t("Digital-human on Sourceforge"),r(o)])]),e("li",null,[e("a",P,[t("The World of Digital Humans: Where AI Meets Realism"),r(o)])]),e("li",null,[e("a",Y,[t("awesome-digital-human"),r(o)])]),e("li",null,[e("a",J,[t("Digital Human Software for Blender"),r(o)])])]),U,e("p",null,[e("a",Q,[t("motexture/VSeq2VSeq"),r(o)]),Z,e("a",$,[t("animate anything"),r(o)]),ee,e("a",te,[t("stabilityai/stable-video-diffusion-img2vid-xt"),r(o)])]),oe,e("p",null,[e("a",re,[t("hotshotco/Hotshot-XL"),r(o)]),ne,e("a",ae,[se,r(o)]),le,e("a",ie,[he,r(o)]),ce,e("a",ge,[t("damo-vilab/modelscope-damo-text-to-video-synthesis"),r(o)]),de,e("a",_e,[t("guoyww/animatediff-motion-adapter-v1-5-2"),r(o)]),ue,e("a",fe,[t("camenduru/potat1"),r(o)]),pe,e("a",me,[t("guoyww/animatediff-motion-lora-zoom-in"),r(o)])]),be,e("ol",null,[e("li",null,[e("a",ke,[t("coqui/XTTS-v2"),r(o)]),t(),xe]),e("li",null,[e("a",ve,[t("speechbrain/tts-tacotron2-ljspeech"),r(o)])]),e("li",null,[e("a",ye,[t("facebook/fastspeech2-en-ljspeech"),r(o)]),t(),we]),e("li",null,[e("a",Se,[t("suno/bark-small"),r(o)]),t(),Te]),e("li",null,[e("a",Ve,[t("microsoft/speecht5_tts"),r(o)]),t(),Ce,De,e("a",Ie,[t("SpeechT5 on Github"),r(o)])]),e("li",null,[e("a",Ae,[t("facebook/mms-tts-eng"),r(o)]),Me]),e("li",null,[e("a",Re,[t("suno/bark"),r(o)]),t(),Ee,t(),e("a",qe,[t("Example on Google Colab"),r(o)])])]),He,e("p",null,[e("a",Be,[Ne,r(o)])]),Le,e("p",null,[e("a",Xe,[t("TencentARC/t2i-adapter-sketch-sdxl-1.0"),r(o)]),t(" **"),ze,e("a",Ge,[t("TencentARC/t2iadapter_sketch_sd15v2"),r(o)]),t(" **")]),e("p",null,[e("a",je,[t("cosc/sketchstyle-cutesexyrobutts"),r(o)])]),e("p",null,[e("a",Fe,[t("microsoft/beit-base-patch16-224-pt22k-ft22k"),r(o)]),Ke,e("a",We,[t("Linaqruf/sketch-style-xl-lora"),r(o)])])])}const Qe=n(i,[["render",Oe],["__file","01.ai_models.html.vue"]]);export{Qe as default};
