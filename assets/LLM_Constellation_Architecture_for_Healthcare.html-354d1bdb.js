import{_ as n}from"./plugin-vue_export-helper-c27b6911.js";import{r as s,o as r,c as o,b as a,d as e,e as i,f as l}from"./app-fd2163c3.js";const c={},h={href:"https://people.unisa.edu.au/srecko.joksimovic",target:"_blank",rel:"noopener noreferrer"},d=a("code",null,"meeting summaries",-1),p={href:"https://arxiv.org/pdf/2403.13313",target:"_blank",rel:"noopener noreferrer"},u={href:"https://arxiv.org/html/2403.13313v1#S1",target:"_blank",rel:"noopener noreferrer"},m=l('<h2 id="abstract" tabindex="-1"><a class="header-anchor" href="#abstract" aria-hidden="true">#</a> Abstract</h2><p>We develop Polaris 1, the first safety-focused Large Language Model (LLM) constellation for real-time patient-AI healthcare conversations. Unlike prior LLM works in healthcare, which focus on tasks like question answering, <span style="color:orange;">our work specifically focuses on long multi-turn voice conversations</span>. Our <span style="color:orange;">one-trillion parameter constellation system</span> is composed of <span style="color:orange;">several multi-billion parameter LLMs</span> as co-operative agents: <span style="color:orange;">a stateful primary agent</span> that focuses on driving an engaging patient-friendly conversation and <span style="color:orange;">several specialist support agents</span> focused on healthcare tasks performed by nurses, social workers, and nutritionists to increase safety and reduce hallucinations. We develop a sophisticated training protocol for iterative co-training of the agents that optimize for diverse objectives.</p><p>We train our models on proprietary data, clinical care plans, healthcare regulatory documents, medical manuals, and other medical reasoning documents. We further align our models to speak like medical professionals, using organic healthcare conversations and simulated ones between patient actors and experienced care-management nurses. This allows our system to express unique capabilities such as rapport building, trust building, empathy and bedside manner augmented with advanced medical reasoning.</p><p>Finally, we present the first comprehensive clinician evaluation of an LLM system for healthcare. We recruited over 1100 U.S. licensed nurses and over 130 U.S. licensed physicians to perform end-to-end conversational evaluations of our system by posing as patients and rating the system on several fine-grained measures. We demonstrate Polaris performs on par with human nurses on aggregate across dimensions such as medical safety, clinical readiness, patient education, conversational quality, and bedside manner. Additionally, we conduct a challenging task-based evaluation of the individual specialist support agents, where we demonstrate our LLM agents significantly outperform a much larger general-purpose LLM (GPT-4) as well as one from its own medium-size class (LLaMA-2 70B).</p><h2 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction" aria-hidden="true">#</a> Introduction</h2><figure><img src="https://arxiv.org/html/2403.13313v1/x1.png" alt="Figure 1:High level overview of our LLM constellation architecture Polaris." tabindex="0" loading="lazy"><figcaption>Figure 1:High level overview of our LLM constellation architecture Polaris.</figcaption></figure><div class="hint-container info"><p class="hint-container-title">Note</p><p>(a)Overview of our architecture, comprising of the Automatic Speech Recognition (ASR) for speech transcription, Polaris for processing the textual utterances, and Text-To-Speech (TTS) for the audio output. The constellation within Polaris contains a primary LLM agent driving the conversation, and several specialist LLM agents providing task-specific context to it.</p></div><div style="display:flex;"><div style="flex:1;"><figure><img src="https://arxiv.org/html/2403.13313v1/x2.png" alt="(b)Conversation snippet between Polaris and a simulated Patient, emphasizing empathy and rapport building as part of good bedside manner, while providing accurate medical information using lab specialist agent’s assistance." tabindex="0" loading="lazy"><figcaption>(b)Conversation snippet between Polaris and a simulated Patient, emphasizing empathy and rapport building as part of good bedside manner, while providing accurate medical information using lab specialist agent’s assistance.</figcaption></figure></div><div style="flex:1;"><figure><img src="https://arxiv.org/html/2403.13313v1/extracted/5481978/images/result-main.png" alt="(c)Comparative evaluation between human nurses (U.S. licensed) and Polaris on bedside manner (e.g., empathy, trust, rapport), medical safety, patient education, clinical readiness and overall conversation quality. Overall, Polaris is strikingly close to human nurse performance, and even outperforms them on some key dimensions." tabindex="0" loading="lazy"><figcaption>(c)Comparative evaluation between human nurses (U.S. licensed) and Polaris on bedside manner (e.g., empathy, trust, rapport), medical safety, patient education, clinical readiness and overall conversation quality. Overall, Polaris is strikingly close to human nurse performance, and even outperforms them on some key dimensions.</figcaption></figure></div></div><p>Recent progress in large language models (LLMs) has shown their impressive capability to plan, reason and interact with humans for a variety of tasks such as web search web, coding Bird et al. (2023), and intelligent content creation Ray (2023). The scaling of LLMs and the datasets used to train them, together with new architectural advances has contributed greatly to the advances in AI capabilities, and shown to surpass human performance in various benchmark tasks sur. These new capabilities are enabling real-world applications that were impossible until very recently such as those in healthcare.</p><p><strong>Healthcare specialization.</strong> Amidst the several domains and applications, healthcare remains a high-stake domain where errors may have fatal implications. The advent of GPT-4 Achiam et al. (2023) has led to a profound surge in the use of AI for healthcare applications, including clinical note and electronic health record processing (see Lee et al. (2023) for overview). While systems like MedPALM Singhal et al. (2023a) and GPT-4 have shown impressive results in general medical benchmarks like USMLE, recent work shows significant error rate for more specialized use-cases like pediatrics Barile et al. (2024). Among the failures, researchers observe that the AI systems struggle to spot known relationships between conditions that an experienced physician would look for, e.g., for a patient with autism, a physician might check for dietary deficiencies. Jacobsen and DeNiro (2017). The researchers note that these systems could be improved by selectively training on accurate and high quality medical literature, not just general articles over the internet, which are typically what most LLMs are trained on. Furthermore, it is possible that the base knowledge about autism leading to nutrient deficiencies is present in the LLMs; what is missing is the medical reasoning to connect the dots (i.e., some patients with autism exhibit narrow dietary preferences, which can then lead to nutrient deficiencies).</p><p><strong>Conversational Healthcare Systems.</strong> Most of the existing works for generative AI in healthcare are focused on tasks like medical question-answering Singhal et al. (2023b) and EHR summarization Veen et al. (2024). There are very few works focusing on natural dialogue between caregivers and patients. More recently, Tu et al. developed Articulate Medical Intelligence Explorer (AMIE) Tu et al. (2024a), which outlines the importance of diagnostic dialogue to enable physicians to make diagnoses and develop management plans. AMIE is presented as a tool for physicians, and focused on diagnostic use cases. There remains a gap in work addressing the broader range of conversations between a care team and a patient that are neither diagnostic, nor directed to clinical decision making, such as inquiring whether a patient is adhering to their prescription, whether they are following the physician’s pre- and post-procedure directions, and general wellness check-ins. While non-diagnostic, these conversations must still be medically accurate, and critically, must build rapport and trust with the patient to make them feel safe, supported, and confident in their care, while communicating with empathy and bedside manner. Such relationship has shown to lead to better patient satisfaction and, ultimately, better outcomes in real world Derksen et al. (2013). General-purpose LLM’s, however, are not optimized for such objectives. Furthermore, these LLM’s are also not optimized for real-time, voice-based conversations, which can be quite different from text-based conversations. For instance, factors such as response length, quality of voice, pauses and interrupts greatly impact the subjective experience.</p><p><strong>The case for AI-based Healthcare Agents.</strong> The US healthcare industry is facing a massive shortage of healthcare workers, that became even more apparent after the COVID-19 pandemic ora. Exacerbated by burnout, stress and financial conditions, 16.7% of hospitals anticipated a critical staffing shortage in 2023 according to the Department of Health and Human Service AHA. The U.S. Bureau of Labor Statistics estimates the need to fill over 200,000 nursing positions every year until 2031 Fac. A 2023 survey found that 28.7% percent of nurses were considering to leave their jobs. The trend in the decline of the US workforce indicates a shortage of more than 4 million workers nationwide by 2026 ora. In the meantime, the demand for healthcare continues to grow as the population continues to age. There are currently 46 million adults over 65, and it will increase to 64 million by 2030, and 90 million by 2050 Agi.</p><p>Given this massive gap in supply and demand for healthcare workers, and the recent promise of Generative AI to supercharge productivity, we focus on developing a non-diagnostic technology for healthcare workforce augmentation, which we denote as super-staffing. In this work, we develop autonomous generative AI healthcare agents that can safely converse with patients on medical topics. Our goal is to improve patient healthcare outcomes by providing a scalable and safe system that can handle non-diagnostic communications. Such a system will allow the human healthcare providers to focus on top-of-license diagnostic and clinical tasks, thereby helping to alleviate staffing shortages. The agents are designed with built-in safety guardrails that ensure appropriate human supervision.</p><p>Our solution is a multi-agent system with highly specialized healthcare LLMs. The following are the primary contributions of our work.</p><p><strong>Architecture and Training.</strong> We develop a unique multi-agent LLM constellation architecture optimized for real-time healthcare conversation. We employ a primary conversational agent with several specialist support agents for a patient-friendly and medically accurate conversation. The primary agent is trained to be aligned with nurse-like conversations geared for building trust, rapport and empathy with patients, as well as accomplishing healthcare-specific tasks typically performed by nurses, medical assistants, social workers, and nutritionists. We develop techniques to make the primary agent stateful to navigate through a long checklist of care protocols. Our support agents are specialized in healthcare tasks that require a high-level of accuracy, such as confirming that the patient’s reported medicine consumption aligns with the dosage prescribed by their physician, determining whether the patient’s reported OTC drug consumption is within the manufacturer’s recommended range, understanding which medicine the patient is referring to (i.e., patients often struggle with correctly pronouncing drug names, and may confuse ones that sound similar), retrieving current and historical lab results from the patient’s EHR, guiding the patient’s food choices to align with their prescribed diet, etc. The specialist agents provide the relevant context to the primary agent in a message-passing framework, which drives the main conversation.<span style="color:orange;">To this end, we develop custom training protocols for conversational alignment using organic healthcare conversations and simulated ones using patient actors and nurses (U.S. licensed) with agents- and clinicians-in-the-loop for co-operative learning.</span></p><p><strong>Safety.</strong> We adopt a three-pronged approach to safety comprised of: (1) A 70B-100B primary model trained using evidence based content; (2) a novel constellation architecture with multiple models totaling over one trillion parameters, in which a primary LLM is supervised by multiple specialist support models to improve medical accuracy and substantially reduce hallucinations; (3) built-in guardrails that bring in a human supervisor when necessary.</p><p><strong>Evaluation.</strong> To the best of our knowledge, we perform the first extensive real-world evaluation of a healthcare LLM system in which we recruited over 1100 US-licensed nurses and over 130 U.S.-licensed physicians posing as patients for our system. This is focused on an integrated system-level conversational evaluation on dimensions such as medical safety, readiness and bedside manners where we demonstrate parity with human nurses on several key metrics. We also perform a challenging component-level evaluation where we demonstrate that our medium-size specialized agents massively outperform a much larger state-of-the-art general-purpose LLM (GPT-4) on the healthcare tasks as well as outperform an LLM from its own parameter size class (LLaMA-2 70B).</p>',17);function g(f,v){const t=s("ExternalLinkIcon");return r(),o("div",null,[a("p",null,[e("Information came from "),a("a",h,[e("George"),i(t)]),e(" in Discord channel "),d,e(" at 1:33pm 4 July 2024.")]),a("p",null,[e('This is the notes for paper "'),a("a",p,[e("Polaris: A Safety-focused LLM Constellation Architecture for Healthcare"),i(t)]),e('". The online version is '),a("a",u,[e("here"),i(t)]),e(".")]),m])}const b=n(c,[["render",g],["__file","LLM_Constellation_Architecture_for_Healthcare.html.vue"]]);export{b as default};
