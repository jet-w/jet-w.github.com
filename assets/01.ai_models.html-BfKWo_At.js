import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as r,a,b as o,o as n}from"./app-D-C-iYev.js";const i={};function l(s,e){return n(),r("div",null,[a(`
## Generate Video
1. stable video diffusion: generate video
1. [Stability-AI](https://github.com/Stability-AI/generative-models?tab=readme-ov-file)`),e[0]||(e[0]=o('<h2 id="building-detection-geoscience" tabindex="-1"><a class="header-anchor" href="#building-detection-geoscience"><span>Building Detection (Geoscience)</span></a></h2><ol><li><a href="https://huggingface.co/datasets/keremberke/satellite-building-segmentation/viewer/mini/test" target="_blank" rel="noopener noreferrer">Datasets for satellite building segmentation</a></li><li><a href="https://huggingface.co/ratnaonline1/segFormer-b4-city-satellite-segmentation-1024x1024" target="_blank" rel="noopener noreferrer">Model for satellite city segmentation</a></li><li><a href="https://www.kaggle.com/code/kmader/segmenting-buildings-in-satellite-images" target="_blank" rel="noopener noreferrer">Segmenting Buildings in Satellite Images</a></li><li><a href="https://huggingface.co/facebook/mask2former-swin-large-mapillary-vistas-panoptic/tree/main" target="_blank" rel="noopener noreferrer">Mask2former swin large mapillary vistas panoptic</a></li><li><a href="https://huggingface.co/thiagohersan/maskformer-satellite-trees" target="_blank" rel="noopener noreferrer">Maskformer Satellite Trees</a></li></ol><h2 id="voice-cloning" tabindex="-1"><a class="header-anchor" href="#voice-cloning"><span>Voice Cloning</span></a></h2><ol><li><a href="https://huggingface.co/dog/kanye" target="_blank" rel="noopener noreferrer">Model for Kanye voice cloning</a></li><li><a href="https://huggingface.co/spaces/akhaliq/Real-Time-Voice-Cloning" target="_blank" rel="noopener noreferrer">Real Time Voice Cloning</a></li><li><a href="https://huggingface.co/anton-l/wav2vec2-xls-r-common_voice-tr-ft-stream" target="_blank" rel="noopener noreferrer">https://huggingface.co/anton-l/wav2vec2-xls-r-common_voice-tr-ft-stream</a></li></ol><h2 id="image-super-resolution" tabindex="-1"><a class="header-anchor" href="#image-super-resolution"><span>Image Super Resolution</span></a></h2><ol><li>Search super-resolution in huggingface</li><li><a href="https://magnific.substack.com/" target="_blank" rel="noopener noreferrer">magnific</a></li><li><a href="https://github.com/IBM/MAX-Image-Resolution-Enhancer" target="_blank" rel="noopener noreferrer">Image Resolution Enhancer (IBM)</a></li><li><a href="https://huggingface.co/keras-io/super-resolution/blob/main/README.md" target="_blank" rel="noopener noreferrer">keras-io/super-resolution</a></li><li><a href="https://huggingface.co/CompVis/ldm-super-resolution-4x-openimages" target="_blank" rel="noopener noreferrer">ldm-super-resolution-4x-openimages</a></li></ol><h2 id="image-clear" tabindex="-1"><a class="header-anchor" href="#image-clear"><span>Image clear</span></a></h2><ol><li><a href="https://huggingface.co/google/maxim-s3-deblurring-gopro" target="_blank" rel="noopener noreferrer">deblur</a></li><li><a href="https://github.com/sayakpaul/maxim-tf" target="_blank" rel="noopener noreferrer">maxim-tf</a></li><li><a href="https://github.com/google-research/maxim" target="_blank" rel="noopener noreferrer">maxim</a></li><li><a href="https://github.com/megvii-research/NAFNet?tab=readme-ov-file" target="_blank" rel="noopener noreferrer">NAFNet</a></li></ol><h2 id="speech2text" tabindex="-1"><a class="header-anchor" href="#speech2text"><span>Speech2Text:</span></a></h2><ol><li><a href="https://huggingface.co/docs/transformers/model_doc/speech_to_text" target="_blank" rel="noopener noreferrer">Speech to Text</a></li><li><a href="https://huggingface.co/docs/transformers/model_doc/speech_to_text_2" target="_blank" rel="noopener noreferrer">Speech to Text 2</a></li><li><a href="https://turboscribe.ai/dashboard" target="_blank" rel="noopener noreferrer">turboscribe.ai</a></li><li><a href="https://huggingface.co/wbbbbb/wav2vec2-large-chinese-zh-cn" target="_blank" rel="noopener noreferrer">wbbbbb/wav2vec2-large-chinese-zh-cn</a> <strong>Important</strong></li><li><a href="https://cloud.google.com/speech-to-text/docs/speech-to-text-supported-languages" target="_blank" rel="noopener noreferrer">Google speech to text supported languages</a></li><li><a href="https://huggingface.co/openai/whisper-large-v3" target="_blank" rel="noopener noreferrer">openai/whisper-large-v3</a></li></ol><h2 id="digital-human" tabindex="-1"><a class="header-anchor" href="#digital-human"><span>Digital Human</span></a></h2><ol><li><a href="https://huggingface.co/CiroN2022/digital-human" target="_blank" rel="noopener noreferrer">CiroN2022/digital-human</a></li><li><a href="https://huggingface.co/Kedreamix/Digital-Human-Weights" target="_blank" rel="noopener noreferrer">Kedreamix/Digital-Human-Weights</a></li><li><a href="https://huggingface.co/papers/2307.05462" target="_blank" rel="noopener noreferrer">Efficient 3D Articulated Human Generation with Layered Surface Volumes</a></li><li><a href="https://huggingface.co/papers/2305.11870" target="_blank" rel="noopener noreferrer">Chupa: Carving 3D Clothed Humans from Skinned Shape Priors using 2D Diffusion Probabilistic Models</a></li><li><a href="https://medium.com/@black_51980/creating-digital-humans-capture-modeling-and-synthesis-1612dbcbcaa4" target="_blank" rel="noopener noreferrer">Creating digital humans: Capture, Modeling, and Synthesis</a></li><li><a href="https://sourceforge.net/software/digital-human/" target="_blank" rel="noopener noreferrer">Digital-human on Sourceforge</a></li><li><a href="https://medium.com/antaeus-ar/the-world-of-digital-humans-where-ai-meets-realism-5e4955b8261c" target="_blank" rel="noopener noreferrer">The World of Digital Humans: Where AI Meets Realism</a></li><li><a href="https://github.com/weihaox/awesome-digital-human" target="_blank" rel="noopener noreferrer">awesome-digital-human</a></li><li><a href="https://sourceforge.net/software/digital-human/integrates-with-blender/" target="_blank" rel="noopener noreferrer">Digital Human Software for Blender</a></li></ol><h2 id="image-to-video" tabindex="-1"><a class="header-anchor" href="#image-to-video"><span>Image to Video</span></a></h2><p><a href="https://huggingface.co/motexture/VSeq2VSeq" target="_blank" rel="noopener noreferrer">motexture/VSeq2VSeq</a><br><a href="https://github.com/alibaba/animate-anything" target="_blank" rel="noopener noreferrer">animate anything</a><br><a href="https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt" target="_blank" rel="noopener noreferrer">stabilityai/stable-video-diffusion-img2vid-xt</a></p><h2 id="text-to-video" tabindex="-1"><a class="header-anchor" href="#text-to-video"><span>Text to Video</span></a></h2><p><a href="https://huggingface.co/hotshotco/Hotshot-XL" target="_blank" rel="noopener noreferrer">hotshotco/Hotshot-XL</a><br><a href="https://huggingface.co/cerspense/zeroscope_v2_576w" target="_blank" rel="noopener noreferrer"><span style="color:orange;font-weight:bold;">cerspense/zeroscope_v2_576w</span></a><br><a href="https://huggingface.co/damo-vilab/text-to-video-ms-1.7b" target="_blank" rel="noopener noreferrer"><span style="color:orange;font-weight:bold;">damo-vilab/text-to-video-ms-1.7b</span></a><br><a href="https://huggingface.co/damo-vilab/modelscope-damo-text-to-video-synthesis" target="_blank" rel="noopener noreferrer">damo-vilab/modelscope-damo-text-to-video-synthesis</a><br><a href="https://huggingface.co/guoyww/animatediff-motion-adapter-v1-5-2" target="_blank" rel="noopener noreferrer">guoyww/animatediff-motion-adapter-v1-5-2</a><br><a href="https://huggingface.co/camenduru/potat1" target="_blank" rel="noopener noreferrer">camenduru/potat1</a><br><a href="https://huggingface.co/guoyww/animatediff-motion-lora-zoom-in" target="_blank" rel="noopener noreferrer">guoyww/animatediff-motion-lora-zoom-in</a></p><h2 id="text-to-speech" tabindex="-1"><a class="header-anchor" href="#text-to-speech"><span>Text to Speech</span></a></h2><ol><li><a href="https://huggingface.co/coqui/XTTS-v2" target="_blank" rel="noopener noreferrer">coqui/XTTS-v2</a> <span style="color:red;font-weight:bold;">Support Chinese, voice clone, emotion, etc..</span></li><li><a href="https://huggingface.co/speechbrain/tts-tacotron2-ljspeech" target="_blank" rel="noopener noreferrer">speechbrain/tts-tacotron2-ljspeech</a></li><li><a href="https://huggingface.co/facebook/fastspeech2-en-ljspeech" target="_blank" rel="noopener noreferrer">facebook/fastspeech2-en-ljspeech</a> <span style="color:orange;">Only English is supported</span></li><li><a href="https://huggingface.co/suno/bark-small" target="_blank" rel="noopener noreferrer">suno/bark-small</a> <span style="">More research is needed, not good enough as example on colab</span></li><li><a href="https://huggingface.co/microsoft/speecht5_tts" target="_blank" rel="noopener noreferrer">microsoft/speecht5_tts</a> <span style="color:orange;">Effect is good, need to find models for other languages</span><br><a href="https://github.com/microsoft/SpeechT5/" target="_blank" rel="noopener noreferrer">SpeechT5 on Github</a></li><li><a href="https://huggingface.co/facebook/mms-tts-eng" target="_blank" rel="noopener noreferrer">facebook/mms-tts-eng</a><span style="color:orange;">Example efficient is good, need to explore for other language.</span></li><li><a href="https://huggingface.co/suno/bark" target="_blank" rel="noopener noreferrer">suno/bark</a> <a href="https://colab.research.google.com/drive/1eJfA2XUa-mXwdMy7DoYKVYHI1iTd9Vkt?usp=sharing#scrollTo=t9Vlr3RRt6B9" target="_blank" rel="noopener noreferrer">Example on Google Colab</a></li></ol><h2 id="text-to-image" tabindex="-1"><a class="header-anchor" href="#text-to-image"><span>Text to Image</span></a></h2><ol><li><a href="https://huggingface.co/dataautogpt3/OpenDalleV1.1" target="_blank" rel="noopener noreferrer"><span style="color:orange;font-weight:bold;">dataautogpt3/OpenDalleV1.1</span></a> <strong>Good</strong></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0" target="_blank" rel="noopener noreferrer"><span style="color:orange;font-weight:bold;">stabilityai/stable-diffusion-xl-base-1.0</span></a> <strong>Better</strong></li></ol><h2 id="sketch" tabindex="-1"><a class="header-anchor" href="#sketch"><span>Sketch</span></a></h2><p><a href="https://huggingface.co/TencentARC/t2i-adapter-sketch-sdxl-1.0" target="_blank" rel="noopener noreferrer">TencentARC/t2i-adapter-sketch-sdxl-1.0</a> **<br><a href="https://huggingface.co/TencentARC/t2iadapter_sketch_sd15v2" target="_blank" rel="noopener noreferrer">TencentARC/t2iadapter_sketch_sd15v2</a> **</p><p><a href="https://huggingface.co/cosc/sketchstyle-cutesexyrobutts" target="_blank" rel="noopener noreferrer">cosc/sketchstyle-cutesexyrobutts</a></p><p><a href="https://huggingface.co/microsoft/beit-base-patch16-224-pt22k-ft22k" target="_blank" rel="noopener noreferrer">microsoft/beit-base-patch16-224-pt22k-ft22k</a><br><a href="https://huggingface.co/Linaqruf/sketch-style-xl-lora" target="_blank" rel="noopener noreferrer">Linaqruf/sketch-style-xl-lora</a></p>',24))])}const h=t(i,[["render",l],["__file","01.ai_models.html.vue"]]),p=JSON.parse(`{"path":"/techniques/AI/Others/01.ai_models.html","title":"AI Models List","lang":"en-US","frontmatter":{"title":"AI Models List","date":"2023-11-27T00:00:00.000Z","icon":"circle-dot","author":"Haiyue","category":["AI"],"tag":["resources"],"star":false,"sticky":false,"description":"Building Detection (Geoscience) Datasets for satellite building segmentation Model for satellite city segmentation Segmenting Buildings in Satellite Images Mask2former swin larg...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://jet-w.github.io/techniques/AI/Others/01.ai_models.html"}],["meta",{"property":"og:site_name","content":"Haiyue's Blog"}],["meta",{"property":"og:title","content":"AI Models List"}],["meta",{"property":"og:description","content":"Building Detection (Geoscience) Datasets for satellite building segmentation Model for satellite city segmentation Segmenting Buildings in Satellite Images Mask2former swin larg..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"article:author","content":"Haiyue"}],["meta",{"property":"article:tag","content":"resources"}],["meta",{"property":"article:published_time","content":"2023-11-27T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"AI Models List\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-11-27T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Haiyue\\"}]}"]]},"headers":[{"level":2,"title":"Building Detection (Geoscience)","slug":"building-detection-geoscience","link":"#building-detection-geoscience","children":[]},{"level":2,"title":"Voice Cloning","slug":"voice-cloning","link":"#voice-cloning","children":[]},{"level":2,"title":"Image Super Resolution","slug":"image-super-resolution","link":"#image-super-resolution","children":[]},{"level":2,"title":"Image clear","slug":"image-clear","link":"#image-clear","children":[]},{"level":2,"title":"Speech2Text:","slug":"speech2text","link":"#speech2text","children":[]},{"level":2,"title":"Digital Human","slug":"digital-human","link":"#digital-human","children":[]},{"level":2,"title":"Image to Video","slug":"image-to-video","link":"#image-to-video","children":[]},{"level":2,"title":"Text to Video","slug":"text-to-video","link":"#text-to-video","children":[]},{"level":2,"title":"Text to Speech","slug":"text-to-speech","link":"#text-to-speech","children":[]},{"level":2,"title":"Text to Image","slug":"text-to-image","link":"#text-to-image","children":[]},{"level":2,"title":"Sketch","slug":"sketch","link":"#sketch","children":[]}],"readingTime":{"minutes":2.27,"words":681},"filePathRelative":"techniques/AI/Others/01.ai_models.md","localizedDate":"November 27, 2023","excerpt":"<!--\\n## Generate Video\\n1. stable video diffusion: generate video\\n1. [Stability-AI](https://github.com/Stability-AI/generative-models?tab=readme-ov-file)-->\\n<h2>Building Detection (Geoscience)</h2>\\n<ol>\\n<li><a href=\\"https://huggingface.co/datasets/keremberke/satellite-building-segmentation/viewer/mini/test\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Datasets for satellite building segmentation</a></li>\\n<li><a href=\\"https://huggingface.co/ratnaonline1/segFormer-b4-city-satellite-segmentation-1024x1024\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Model for satellite city segmentation</a></li>\\n<li><a href=\\"https://www.kaggle.com/code/kmader/segmenting-buildings-in-satellite-images\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Segmenting Buildings in Satellite Images</a></li>\\n<li><a href=\\"https://huggingface.co/facebook/mask2former-swin-large-mapillary-vistas-panoptic/tree/main\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Mask2former swin large mapillary vistas panoptic</a></li>\\n<li><a href=\\"https://huggingface.co/thiagohersan/maskformer-satellite-trees\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Maskformer Satellite Trees</a></li>\\n</ol>","autoDesc":true}`);export{h as comp,p as data};
